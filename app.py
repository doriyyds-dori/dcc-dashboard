import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from datetime import datetime

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")

st.markdown("""
<style>
    .top-container {display: flex; align-items: center; justify-content: space-between; padding-bottom: 20px; border-bottom: 2px solid #f0f0f0;}
    .metric-card {background-color: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    div[data-testid="stSelectbox"] {min-width: 200px;}
    .big-font {font-size: 18px !important; font-weight: bold;}
    /* ä¼˜åŒ–æäº¤æŒ‰é’®æ ·å¼ */
    div[data-testid="stFormSubmitButton"] button {
        width: 100%;
        background-color: #bb0a30;
        color: white;
        border: none;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ================= 2. å®‰å…¨é”ä¸æ–‡ä»¶å­˜å‚¨ =================
ADMIN_PASSWORD = "AudiSARR3" 

DATA_DIR = "data_store"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)
PATH_F = os.path.join(DATA_DIR, "funnel.xlsx")      # 1. æ¼æ–—
PATH_D = os.path.join(DATA_DIR, "dcc.xlsx")         # 2. é¡¾é—®è´¨æ£€
PATH_A = os.path.join(DATA_DIR, "ams.xlsx")         # 3. AMS
PATH_S = os.path.join(DATA_DIR, "store_rank.csv")   # 4. é—¨åº—æ’å

def save_uploaded_file(uploaded_file, save_path):
    # å¼ºåˆ¶è¦†ç›–ä¿å­˜
    with open(save_path, "wb") as f: f.write(uploaded_file.getbuffer())
    return True

# ================= 3. ä¾§è¾¹æ é€»è¾‘ (ä½¿ç”¨ Form è§£å†³ç‚¹å‡»æ— ååº”é—®é¢˜) =================
with st.sidebar:
    st.header("âš™ï¸ ç®¡ç†é¢æ¿")
    has_data = os.path.exists(PATH_F) and os.path.exists(PATH_D) and os.path.exists(PATH_A) and os.path.exists(PATH_S)
    
    if has_data: st.success("âœ… æ•°æ®çŠ¶æ€ï¼šå·²å°±ç»ª")
    else: st.warning("âš ï¸ æš‚æ— æ•°æ®")
    st.markdown("---")
    
    with st.expander("ğŸ” æ›´æ–°æ•°æ® (ä»…é™ç®¡ç†å‘˜)", expanded=True):
        pwd = st.text_input("è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")
        
        if pwd == ADMIN_PASSWORD:
            st.info("ğŸ”“ èº«ä»½éªŒè¯é€šè¿‡ï¼Œè¯·ä¸Šä¼ æ•°æ®ï¼š")
            
            # --- ä½¿ç”¨ st.form ç¡®ä¿æäº¤ç¨³å®š ---
            with st.form("data_update_form", clear_on_submit=False):
                st.markdown("##### å¿…é¡»ä¸Šä¼ æ‰€æœ‰ 4 ä¸ªæ–‡ä»¶ï¼š")
                new_f = st.file_uploader("1. æ¼æ–—æŒ‡æ ‡è¡¨", type=["xlsx", "csv"])
                new_d = st.file_uploader("2. é¡¾é—®è´¨æ£€è¡¨", type=["xlsx", "csv"])
                new_a = st.file_uploader("3. AMSè·Ÿè¿›è¡¨", type=["xlsx", "csv"])
                new_s = st.file_uploader("4. é—¨åº—æ’åè¡¨", type=["xlsx", "csv"]) 
                
                # æäº¤æŒ‰é’®
                submitted = st.form_submit_button("ğŸš€ ç¡®è®¤å¹¶æ›´æ–°æ•°æ®")
                
                if submitted:
                    if new_f and new_d and new_a and new_s:
                        with st.spinner("æ­£åœ¨ä¿å­˜æ–‡ä»¶å¹¶å¤„ç†..."):
                            save_uploaded_file(new_f, PATH_F)
                            save_uploaded_file(new_d, PATH_D)
                            save_uploaded_file(new_a, PATH_A)
                            save_uploaded_file(new_s, PATH_S)
                        
                        st.success("âœ… æ•°æ®æ›´æ–°æˆåŠŸï¼é¡µé¢å³å°†åˆ·æ–°...")
                        st.rerun()
                    else:
                        st.error("âŒ æ›´æ–°å¤±è´¥ï¼šè¯·ç¡®ä¿ 4 ä¸ªæ–‡ä»¶å…¨éƒ¨éƒ½å·²ä¸Šä¼ ã€‚")
        elif pwd:
            st.error("å¯†ç é”™è¯¯")

# ================= 4. æ•°æ®å¤„ç†é€»è¾‘ (å¢å¼ºå®¹é”™) =================
def smart_read(file_path, is_rank_file=False):
    """æ™ºèƒ½è¯»å–ï¼Œæ”¯æŒcsv/xlsxï¼Œé’ˆå¯¹æ’åè¡¨æ”¯æŒè·³è¿‡é¦–è¡Œ"""
    try:
        if isinstance(file_path, str):
            is_csv = file_path.endswith('.csv') or file_path.endswith('.txt')
        else:
            is_csv = file_path.name.endswith('.csv') or file_path.name.endswith('.txt')
            
        if is_csv:
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path)
            
        # é’ˆå¯¹é—¨åº—æ’åè¡¨çš„ç‰¹æ®Šå¤„ç† (æ£€æµ‹æ˜¯å¦åŒ…å« metadata å¤´)
        if is_rank_file:
            # å®šä¹‰æˆ‘ä»¬åœ¨æ‰¾çš„å…³é”®åˆ—
            target_cols = ['é—¨åº—åç§°', 'è´¨æ£€æ€»åˆ†', 'æ’å']
            # å¦‚æœç¬¬ä¸€è¡Œè¡¨å¤´é‡Œæ²¡æ‰¾åˆ°è¿™äº›åˆ—ï¼Œå°è¯•è¯»ç¬¬äºŒè¡Œä½œä¸ºè¡¨å¤´
            if not any(col in df.columns for col in target_cols):
                if is_csv: df = pd.read_csv(file_path, header=1)
                else: df = pd.read_excel(file_path, header=1)
        return df
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        return None

def clean_percent_col(df, col_name):
    if col_name not in df.columns: return
    series = df[col_name].astype(str).str.strip().str.replace('%', '', regex=False)
    numeric_series = pd.to_numeric(series, errors='coerce').fillna(0)
    if numeric_series.max() > 1.0:
        df[col_name] = numeric_series / 100
    else:
        df[col_name] = numeric_series

def safe_div(df, num_col, denom_col):
    num = pd.to_numeric(df[num_col], errors='coerce').fillna(0)
    denom = pd.to_numeric(df[denom_col], errors='coerce').fillna(0)
    return (num / denom).replace([np.inf, -np.inf], 0).fillna(0)

def process_data(path_f, path_d, path_a, path_s):
    try:
        raw_f = smart_read(path_f)
        raw_d = smart_read(path_d)
        raw_a = smart_read(path_a)
        raw_s = smart_read(path_s, is_rank_file=True)
        
        # åªè¦æœ‰ä¸€ä¸ªæ–‡ä»¶æ²¡è¯»å‡ºæ¥ï¼Œå°±è¿”å› None
        if raw_f is None or raw_d is None or raw_a is None or raw_s is None: 
            return None, None

        # ================= A. Funnel (æ¼æ–—) =================
        # æ¨¡ç³ŠåŒ¹é…åˆ—åï¼Œå¢åŠ é²æ£’æ€§
        store_col = next((c for c in raw_f.columns if 'ä»£ç†å•†' in str(c) or 'é—¨åº—' in str(c)), raw_f.columns[0])
        name_col = next((c for c in raw_f.columns if 'ç®¡å®¶' in str(c) or 'é¡¾é—®' in str(c)), raw_f.columns[1])
        col_leads = 'çº¿ä¸Š_æœ‰æ•ˆçº¿ç´¢æ•°' if 'çº¿ä¸Š_æœ‰æ•ˆçº¿ç´¢æ•°' in raw_f.columns else 'çº¿ç´¢é‡'
        col_visits = 'çº¿ä¸Š_åˆ°åº—æ•°' if 'çº¿ä¸Š_åˆ°åº—æ•°' in raw_f.columns else 'åˆ°åº—é‡'
        col_excel_rate = next((c for c in raw_f.columns if 'ç‡' in str(c) and ('åˆ°åº—' in str(c) or 'æœ‰æ•ˆ' in str(c))), None)

        rename_dict = {store_col: 'é—¨åº—åç§°', name_col: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', col_leads: 'çº¿ç´¢é‡', col_visits: 'åˆ°åº—é‡'}
        if col_excel_rate: rename_dict[col_excel_rate] = 'Excel_Rate'
        
        df_f = raw_f.rename(columns=rename_dict)
        # åŒºåˆ†é—¨åº—è¡Œå’Œé¡¾é—®è¡Œ
        df_store_data = df_f[df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('å°è®¡', na=False)].copy()
        df_advisor_data = df_f[~df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('è®¡|-', na=False)].copy()

        for df in [df_store_data, df_advisor_data]:
            df['çº¿ç´¢é‡'] = pd.to_numeric(df['çº¿ç´¢é‡'], errors='coerce').fillna(0)
            df['åˆ°åº—é‡'] = pd.to_numeric(df['åˆ°åº—é‡'], errors='coerce').fillna(0)
            if 'Excel_Rate' in df.columns:
                clean_percent_col(df, 'Excel_Rate')
                df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = df['Excel_Rate']
            else:
                df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = safe_div(df, 'åˆ°åº—é‡', 'çº¿ç´¢é‡')
            df['çº¿ç´¢åˆ°åº—ç‡'] = (df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100).map('{:.1f}%'.format)

        # ================= B. DCC (é¡¾é—®è´¨æ£€) =================
        wechat_col = 'æ·»åŠ å¾®ä¿¡.1' if 'æ·»åŠ å¾®ä¿¡.1' in raw_d.columns else 'æ·»åŠ å¾®ä¿¡'
        df_d = raw_d.rename(columns={
            'é¡¾é—®åç§°': 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'è´¨æ£€æ€»åˆ†': 'è´¨æ£€æ€»åˆ†',
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        })
        # å…¼å®¹å¤„ç†
        if wechat_col in raw_d.columns:
            df_d['S_Wechat'] = raw_d[wechat_col]
        else:
            df_d['S_Wechat'] = 0
        
        score_cols = ['è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat', 'S_Time']
        for c in score_cols:
            if c in df_d.columns:
                df_d[c] = pd.to_numeric(df_d[c], errors='coerce') 
        
        # åªå–å­˜åœ¨çš„åˆ—
        existing_cols = [c for c in (['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] + score_cols) if c in df_d.columns]
        df_d = df_d[existing_cols]

        # ================= C. Store Scores (é—¨åº—è´¨æ£€ - ç›´æ¥è¯»å–æ–‡ä»¶4) =================
        df_s = raw_s.rename(columns={
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        })
        s_wechat_col = 'æ·»åŠ å¾®ä¿¡.1' if 'æ·»åŠ å¾®ä¿¡.1' in raw_s.columns else 'æ·»åŠ å¾®ä¿¡'
        if s_wechat_col in raw_s.columns:
            df_s['S_Wechat'] = raw_s[s_wechat_col]
        else:
            df_s['S_Wechat'] = 0
        
        store_score_cols = ['é—¨åº—åç§°', 'è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat', 'S_Time']
        available_store_cols = [c for c in store_score_cols if c in df_s.columns]
        df_s = df_s[available_store_cols]
        for c in available_store_cols:
            if c != 'é—¨åº—åç§°':
                df_s[c] = pd.to_numeric(df_s[c], errors='coerce')

        # ================= D. AMS (è·Ÿè¿›æ•°æ®) =================
        # æ¨¡ç³ŠåŒ¹é… AMS åˆ—å
        cols_config = [
            ({'ç®¡å®¶å§“å'}, 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶'),
            ({'DCCå¹³å‡é€šè¯æ—¶é•¿'}, 'é€šè¯æ—¶é•¿'),
            ({'DCCæ¥é€šçº¿ç´¢æ•°'}, 'conn_num'), ({'DCCå¤–å‘¼çº¿ç´¢æ•°'}, 'conn_denom'),
            ({'DCCåŠæ—¶å¤„ç†çº¿ç´¢'}, 'timely_num'), ({'éœ€å¤–å‘¼çº¿ç´¢æ•°'}, 'timely_denom'),
            ({'äºŒæ¬¡å¤–å‘¼çº¿ç´¢æ•°'}, 'call2_num'), ({'éœ€å†å‘¼çº¿ç´¢æ•°'}, 'call2_denom'),
            ({'DCCä¸‰æ¬¡å¤–å‘¼çš„çº¿ç´¢æ•°', 'ä¸‰æ¬¡å¤–å‘¼çº¿ç´¢æ•°'}, 'call3_num'), 
            ({'DCCäºŒå‘¼çŠ¶æ€ä¸ºéœ€å†å‘¼çš„çº¿ç´¢æ•°', 'äºŒå‘¼çŠ¶æ€ä¸ºéœ€å†å‘¼'}, 'call3_denom')
        ]
        found_rename_map = {}
        for keywords, target_name in cols_config:
            found_col = None
            for col in raw_a.columns:
                for k in keywords:
                    if k in str(col).strip(): found_col = col; break
                if found_col: break
            if found_col: found_rename_map[found_col] = target_name
        
        df_a = raw_a.rename(columns=found_rename_map)
        
        all_ams_calc_cols = ['conn_num', 'conn_denom', 'timely_num', 'timely_denom', 
                             'call2_num', 'call2_denom', 'call3_num', 'call3_denom']
        for c in all_ams_calc_cols:
            if c not in df_a.columns: df_a[c] = 0
            else: df_a[c] = pd.to_numeric(df_a[c], errors='coerce').fillna(0)

        df_a['å¤–å‘¼æ¥é€šç‡'] = safe_div(df_a, 'conn_num', 'conn_denom')
        df_a['DCCåŠæ—¶å¤„ç†ç‡'] = safe_div(df_a, 'timely_num', 'timely_denom')
        df_a['DCCäºŒæ¬¡å¤–å‘¼ç‡'] = safe_div(df_a, 'call2_num', 'call2_denom')
        df_a['DCCä¸‰æ¬¡å¤–å‘¼ç‡'] = safe_div(df_a, 'call3_num', 'call3_denom')

        final_ams_cols = ['é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'é€šè¯æ—¶é•¿', 'å¤–å‘¼æ¥é€šç‡', 'DCCåŠæ—¶å¤„ç†ç‡', 'DCCäºŒæ¬¡å¤–å‘¼ç‡', 'DCCä¸‰æ¬¡å¤–å‘¼ç‡'] + all_ams_calc_cols
        # ä»…ä¿ç•™å­˜åœ¨çš„åˆ—
        final_ams_cols = [c for c in final_ams_cols if c in df_a.columns]
        df_a = df_a[final_ams_cols]

        # ================= E. Merge =================
        # æ¸…ç†ç©ºæ ¼
        for df in [df_store_data, df_advisor_data, df_d, df_a, df_s]:
            if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' in df.columns: df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] = df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.strip()
            if 'é—¨åº—åç§°' in df.columns: df['é—¨åº—åç§°'] = df['é—¨åº—åç§°'].astype(str).str.strip()

        # 1. é¡¾é—®å…¨é‡è¡¨
        full_advisors = pd.merge(df_advisor_data, df_d, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        full_advisors = pd.merge(full_advisors, df_a, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        
        cols_to_fill_zero = ['çº¿ç´¢é‡', 'åˆ°åº—é‡', 'é€šè¯æ—¶é•¿'] + all_ams_calc_cols
        # åªå¡«å……å­˜åœ¨çš„åˆ—
        cols_to_fill_zero = [c for c in cols_to_fill_zero if c in full_advisors.columns]
        full_advisors[cols_to_fill_zero] = full_advisors[cols_to_fill_zero].fillna(0)

        # 2. é—¨åº—å…¨é‡è¡¨ (AMS èšåˆ + è´¨æ£€è¡¨è¯»å–)
        ams_agg_dict = {
            'conn_num': 'sum', 'conn_denom': 'sum',
            'timely_num': 'sum', 'timely_denom': 'sum',
            'call2_num': 'sum', 'call2_denom': 'sum',
            'call3_num': 'sum', 'call3_denom': 'sum'
        }
        # ç¡®ä¿èšåˆåˆ—å­˜åœ¨
        valid_agg = {k:v for k,v in ams_agg_dict.items() if k in full_advisors.columns}
        
        store_ams = full_advisors.groupby('é—¨åº—åç§°').agg(valid_agg).reset_index()
        
        store_ams['å¤–å‘¼æ¥é€šç‡'] = safe_div(store_ams, 'conn_num', 'conn_denom')
        store_ams['DCCåŠæ—¶å¤„ç†ç‡'] = safe_div(store_ams, 'timely_num', 'timely_denom')
        store_ams['DCCäºŒæ¬¡å¤–å‘¼ç‡'] = safe_div(store_ams, 'call2_num', 'call2_denom')
        store_ams['DCCä¸‰æ¬¡å¤–å‘¼ç‡'] = safe_div(store_ams, 'call3_num', 'call3_denom')

        full_stores = pd.merge(df_store_data, df_s, on='é—¨åº—åç§°', how='left')
        full_stores = pd.merge(full_stores, store_ams, on='é—¨åº—åç§°', how='left')
        
        return full_advisors, full_stores

    except Exception as e:
        # è¿™ä¸ª error ä¼šåœ¨ä¸‹é¢ç•Œé¢ä¸­è¢«æ•è·å¹¶æ‰“å°
        print(f"Process Error: {e}")
        return None, None

# ================= 5. ç•Œé¢æ¸²æŸ“ (å¸¦è°ƒè¯•è¯Šæ–­) =================
if has_data:
    # å¢åŠ  loading æç¤º
    with st.spinner("æ­£åœ¨è¯»å–å¹¶å¤„ç†æ•°æ®..."):
        df_advisors, df_stores = process_data(PATH_F, PATH_D, PATH_A, PATH_S)
    
    # --- å¤±è´¥è¯Šæ–­å— ---
    if df_advisors is None:
        st.error("âŒ æ•°æ®å¤„ç†å¤±è´¥ï¼è¯·æ£€æŸ¥ä¸‹æ–¹è¯Šæ–­ä¿¡æ¯ï¼š")
        st.markdown("### ğŸ” åŸå§‹æ–‡ä»¶è¯Šæ–­æŠ¥å‘Š")
        
        st.write("---")
        st.write("ğŸ“‚ **1. é—¨åº—æ’åè¡¨ (Raw Data Preview)**")
        try:
            raw_s = smart_read(PATH_S, is_rank_file=True)
            if raw_s is not None:
                st.dataframe(raw_s.head(3))
                st.write("**æ£€æµ‹åˆ°çš„åˆ—å:**", list(raw_s.columns))
                if 'é—¨åº—åç§°' not in raw_s.columns:
                    st.error("âš ï¸ é”™è¯¯ï¼šåœ¨æ’åè¡¨ä¸­æ‰¾ä¸åˆ°ã€é—¨åº—åç§°ã€‘åˆ—ã€‚è¯·æ£€æŸ¥è¡¨å¤´æ˜¯å¦æ­£ç¡®ã€‚")
            else:
                st.error("æ— æ³•è¯»å–æ’åè¡¨æ–‡ä»¶ã€‚")
        except Exception as e:
            st.error(f"è¯»å–å¼‚å¸¸: {e}")

        st.write("---")
        st.write("ğŸ“‚ **2. æ¼æ–—è¡¨ (Raw Data Preview)**")
        try:
            raw_f = smart_read(PATH_F)
            if raw_f is not None:
                st.dataframe(raw_f.head(3))
            else: st.error("æ— æ³•è¯»å–æ¼æ–—è¡¨ã€‚")
        except: pass
        
        st.warning("è¯·æ ¹æ®ä¸Šè¿°è¡¨å¤´ä¿¡æ¯ï¼Œè°ƒæ•´æ‚¨çš„Excelæ–‡ä»¶åˆ—åï¼Œæˆ–è€…é‡æ–°ä¸Šä¼ ã€‚")

    else:
        # --- æ•°æ®æ­£å¸¸ï¼Œæ¸²æŸ“çœ‹æ¿ ---
        
        col_header, col_filter = st.columns([3, 1])
        with col_header: st.title("Audi | DCC æ•ˆèƒ½çœ‹æ¿")
        with col_filter:
            if not df_stores.empty: all_stores = sorted(list(df_stores['é—¨åº—åç§°'].unique()))
            else: all_stores = sorted(list(df_advisors['é—¨åº—åç§°'].unique()))
            store_options = ["å…¨éƒ¨"] + all_stores
            selected_store = st.selectbox("ğŸ­ åˆ‡æ¢é—¨åº—è§†å›¾", store_options)

        # å‡†å¤‡å½“å‰è§†å›¾æ•°æ®
        if selected_store == "å…¨éƒ¨":
            current_df = df_stores.copy()
            current_df['åç§°'] = current_df['é—¨åº—åç§°']
            rank_title = "ğŸ† å…¨åŒºé—¨åº—æ’å"
            # KPI è®¡ç®—
            kpi_leads = current_df['çº¿ç´¢é‡'].sum()
            kpi_visits = current_df['åˆ°åº—é‡'].sum()
            kpi_rate = kpi_visits / kpi_leads if kpi_leads > 0 else 0
            # é—¨åº—æ€»åˆ†ç›´æ¥æ±‚å¹³å‡
            kpi_score = current_df['è´¨æ£€æ€»åˆ†'].mean() 
        else:
            current_df = df_advisors[df_advisors['é—¨åº—åç§°'] == selected_store].copy()
            current_df['åç§°'] = current_df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶']
            rank_title = f"ğŸ‘¤ {selected_store} - é¡¾é—®æ’å"
            kpi_leads = current_df['çº¿ç´¢é‡'].sum()
            kpi_visits = current_df['åˆ°åº—é‡'].sum()
            kpi_rate = kpi_visits / kpi_leads if kpi_leads > 0 else 0
            kpi_score = current_df['è´¨æ£€æ€»åˆ†'].mean()

        # 1. KPI Cards
        st.subheader("1ï¸âƒ£ ç»“æœæ¦‚è§ˆ (Result)")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("æ€»æœ‰æ•ˆçº¿ç´¢", f"{int(kpi_leads):,}")
        k2.metric("æ€»å®é™…åˆ°åº—", f"{int(kpi_visits):,}")
        k3.metric("çº¿ç´¢åˆ°åº—ç‡", f"{kpi_rate:.1%}")
        k4.metric("å¹³å‡è´¨æ£€æ€»åˆ†", f"{kpi_score:.1f}")
        
        # 2. Process
        st.markdown("---")
        st.subheader("2ï¸âƒ£ DCC å¤–å‘¼è¿‡ç¨‹ç›‘æ§ (Process)")
        
        p1, p2, p3, p4 = st.columns(4)
        def calc_kpi_rate(df, num, denom):
            if num not in df.columns or denom not in df.columns: return 0
            total_num = df[num].sum()
            total_denom = df[denom].sum()
            return total_num / total_denom if total_denom > 0 else 0

        avg_conn = calc_kpi_rate(current_df, 'conn_num', 'conn_denom')
        avg_timely = calc_kpi_rate(current_df, 'timely_num', 'timely_denom')
        avg_call2 = calc_kpi_rate(current_df, 'call2_num', 'call2_denom')
        avg_call3 = calc_kpi_rate(current_df, 'call3_num', 'call3_denom')
        
        p1.metric("ğŸ“ å¤–å‘¼æ¥é€šç‡", f"{avg_conn:.1%}")
        p2.metric("âš¡ DCCåŠæ—¶å¤„ç†ç‡", f"{avg_timely:.1%}")
        p3.metric("ğŸ”„ äºŒæ¬¡å¤–å‘¼ç‡", f"{avg_call2:.1%}")
        p4.metric("ğŸ” ä¸‰æ¬¡å¤–å‘¼ç‡", f"{avg_call3:.1%}")
        st.caption("æ³¨ï¼šä»¥ä¸Šä¸ºåŠ æƒå¹³å‡å€¼")

        # ç»˜å›¾æ•°æ®å‡†å¤‡
        plot_df_vis = current_df.copy()
        plot_df_vis['è´¨æ£€æ€»åˆ†_æ˜¾ç¤º'] = plot_df_vis['è´¨æ£€æ€»åˆ†'].fillna(0) 

        c_proc_1, c_proc_2 = st.columns(2)
        with c_proc_1:
            st.markdown("#### ğŸ•µï¸ å¼‚å¸¸ä¾¦æµ‹ï¼šDCCå¤–å‘¼æ¥é€šç‡ vs 60ç§’é€šè¯å æ¯”")
            st.info("ğŸ’¡ **åˆ†æé€»è¾‘ï¼š** å³ä¸‹è§’ï¼ˆæ¥é€šç‡é«˜ä½†60ç§’å æ¯”ä½ï¼‰ä»£è¡¨å¯èƒ½å­˜åœ¨â€œäººä¸ºå‹ä½æ—¶é•¿/è¯æœ¯å·®â€é—®é¢˜ã€‚")
            
            # åªæœ‰å½“åˆ—å­˜åœ¨æ—¶æ‰ç»˜å›¾
            if 'S_60s' in plot_df_vis.columns and 'å¤–å‘¼æ¥é€šç‡' in plot_df_vis.columns:
                fig_p1 = px.scatter(
                    plot_df_vis, x="å¤–å‘¼æ¥é€šç‡", y="S_60s", size="çº¿ç´¢é‡", color="è´¨æ£€æ€»åˆ†_æ˜¾ç¤º",
                    hover_name="åç§°", labels={"å¤–å‘¼æ¥é€šç‡": "å¤–å‘¼æ¥é€šç‡", "S_60s": "60ç§’é€šè¯å æ¯”å¾—åˆ†"},
                    color_continuous_scale="RdYlGn", height=350
                )
                fig_p1.add_vline(x=avg_conn, line_dash="dash", line_color="gray")
                fig_p1.add_hline(y=plot_df_vis['S_60s'].mean(), line_dash="dash", line_color="gray")
                fig_p1.update_layout(xaxis=dict(tickformat=".0%"))
                st.plotly_chart(fig_p1, use_container_width=True)
            else:
                st.warning("âš ï¸ ç¼ºå°‘å¿…è¦æ•°æ®ï¼ˆ60ç§’é€šè¯æˆ–æ¥é€šç‡ï¼‰ï¼Œæ— æ³•ç»˜åˆ¶æ•£ç‚¹å›¾ã€‚")

        with c_proc_2:
            st.markdown("#### ğŸ”— å½’å› åˆ†æï¼šè¿‡ç¨‹æŒ‡æ ‡ vs çº¿ç´¢é¦–é‚€åˆ°åº—ç‡")
            st.info("ğŸ’¡ **åˆ†æé€»è¾‘ï¼š** ç›‘æ§å¤–å‘¼åŠæ—¶æ€§ä¸é‚€çº¦åˆ°åº—ç‡ç›¸å…³æ€§ã€‚")
            x_axis_choice = st.radio("é€‰æ‹©æ¨ªè½´æŒ‡æ ‡ï¼š", ["DCCåŠæ—¶å¤„ç†ç‡", "DCCäºŒæ¬¡å¤–å‘¼ç‡", "DCCä¸‰æ¬¡å¤–å‘¼ç‡"], horizontal=True)
            
            if x_axis_choice in plot_df_vis.columns:
                plot_df_corr = plot_df_vis.copy()
                plot_df_corr['è½¬åŒ–ç‡%'] = plot_df_corr['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100
                fig_p2 = px.scatter(
                    plot_df_corr, x=x_axis_choice, y="è½¬åŒ–ç‡%", size="çº¿ç´¢é‡", color="è´¨æ£€æ€»åˆ†_æ˜¾ç¤º",
                    hover_name="åç§°", labels={x_axis_choice: x_axis_choice, "è½¬åŒ–ç‡%": "çº¿ç´¢åˆ°åº—ç‡(%)"},
                    color_continuous_scale="Blues", height=300
                )
                fig_p2.update_layout(xaxis=dict(tickformat=".0%"))
                st.plotly_chart(fig_p2, use_container_width=True)
            else:
                st.warning(f"âš ï¸ ç¼ºå°‘ {x_axis_choice} æ•°æ®ï¼Œæ— æ³•ç»˜å›¾ã€‚")

        st.markdown("---")

        # 3. Rank Table
        c_left, c_right = st.columns([1, 2])
        with c_left:
            st.markdown(f"### ğŸ† {rank_title}")
            rank_df = current_df[['åç§°', 'çº¿ç´¢åˆ°åº—ç‡', 'çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼', 'è´¨æ£€æ€»åˆ†']].copy()
            rank_df['Sort_Score'] = rank_df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'].fillna(-1)
            rank_df = rank_df.sort_values('Sort_Score', ascending=False).head(15)
            display_df = rank_df[['åç§°', 'çº¿ç´¢åˆ°åº—ç‡', 'è´¨æ£€æ€»åˆ†']]
            st.dataframe(
                display_df, hide_index=True, use_container_width=True, height=400,
                column_config={"åç§°": st.column_config.TextColumn("åç§°"), "çº¿ç´¢åˆ°åº—ç‡": st.column_config.TextColumn("çº¿ç´¢åˆ°åº—ç‡"), "è´¨æ£€æ€»åˆ†": st.column_config.NumberColumn("è´¨æ£€æ€»åˆ†", format="%.1f")}
            )

        with c_right:
            st.markdown("### ğŸ’¡ è¯æœ¯è´¨é‡ vs è½¬åŒ–ç»“æœ")
            if 'S_Time' in plot_df_vis.columns:
                plot_df = plot_df_vis.copy()
                plot_df['è½¬åŒ–ç‡%'] = plot_df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100
                fig = px.scatter(
                    plot_df, x="S_Time", y="è½¬åŒ–ç‡%", size="çº¿ç´¢é‡", color="è´¨æ£€æ€»åˆ†_æ˜¾ç¤º", hover_name="åç§°",
                    labels={"S_Time": "æ˜ç¡®åˆ°åº—æ—¶é—´å¾—åˆ†", "è½¬åŒ–ç‡%": "çº¿ç´¢åˆ°åº—ç‡(%)"}, color_continuous_scale="Reds", height=400
                )
                if not plot_df.empty:
                    fig.add_vline(x=plot_df['S_Time'].mean(), line_dash="dash", line_color="gray")
                    fig.add_hline(y=kpi_rate * 100, line_dash="dash", line_color="gray")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("âš ï¸ ç¼ºå°‘â€œæ˜ç¡®åˆ°åº—æ—¶é—´â€æ•°æ®ï¼Œæ— æ³•ç»˜å›¾")

        st.markdown("---")
        
        # 4. Diagnosis
        with st.container():
            st.markdown("### ğŸ•µï¸â€â™€ï¸ é‚€çº¦ä¸“å‘˜/ç®¡å®¶æ·±åº¦è¯Šæ–­")
            if selected_store == "å…¨éƒ¨":
                st.info("ğŸ’¡ è¯·å…ˆåœ¨å³ä¸Šæ–¹é€‰æ‹©å…·ä½“ã€é—¨åº—ã€‘ï¼ŒæŸ¥çœ‹è¯¥é—¨åº—ä¸‹çš„é¡¾é—®è¯¦ç»†è¯Šæ–­ã€‚")
            else:
                diag_df = current_df[current_df['çº¿ç´¢é‡'] > 0].copy()
                diag_list = sorted(diag_df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].unique())
                
                if len(diag_list) > 0:
                    selected_person = st.selectbox("ğŸ” é€‰æ‹©è¯¥åº—é‚€çº¦ä¸“å‘˜/ç®¡å®¶ï¼š", diag_list)
                    p = df_advisors[df_advisors['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] == selected_person].iloc[0]
                    
                    d1, d2, d3 = st.columns([1, 1, 1.2])
                    with d1:
                        st.caption("è½¬åŒ–æ¼æ–— (RESULT)")
                        fig_f = go.Figure(go.Funnel(
                            y = ["çº¿ç´¢é‡", "åˆ°åº—é‡"], x = [p['çº¿ç´¢é‡'], p['åˆ°åº—é‡']],
                            textinfo = "value+percent initial", marker = {"color": ["#d9d9d9", "#bb0a30"]}
                        ))
                        fig_f.update_layout(showlegend=False, height=180, margin=dict(t=0,b=0,l=0,r=0))
                        st.plotly_chart(fig_f, use_container_width=True)
                        st.metric("çº¿ç´¢åˆ°åº—ç‡", p['çº¿ç´¢åˆ°åº—ç‡']) 
                        st.caption(f"å¹³å‡é€šè¯æ—¶é•¿: {p['é€šè¯æ—¶é•¿']:.1f} ç§’")

                    has_score = not pd.isna(p['è´¨æ£€æ€»åˆ†']) and 'S_Time' in p

                    with d2:
                        st.caption("è´¨æ£€å¾—åˆ†è¯¦æƒ… (QUALITY)")
                        if has_score:
                            metrics = {"æ˜ç¡®åˆ°åº—æ—¶é—´": p.get('S_Time'), "60ç§’é€šè¯å æ¯”": p.get('S_60s'), "ç”¨è½¦éœ€æ±‚": p.get('S_Needs'), "è½¦å‹ä¿¡æ¯ä»‹ç»": p.get('S_Car'), "æ”¿ç­–ç›¸å…³è¯æœ¯": p.get('S_Policy'), "æ·»åŠ å¾®ä¿¡": p.get('S_Wechat')}
                            for k, v in metrics.items():
                                c_a, c_b = st.columns([3, 1])
                                val = 0 if pd.isna(v) else v
                                c_a.progress(min(val/100, 1.0))
                                c_b.write(f"{val:.1f}")
                                st.caption(k)
                        else: st.warning("æš‚æ— è´¨æ£€æ•°æ®")

                    with d3:
                        with st.container():
                            if has_score:
                                st.error("ğŸ¤– AI æ™ºèƒ½è¯Šæ–­å»ºè®®")
                                val_60s = 0 if pd.isna(p.get('S_60s')) else p.get('S_60s')
                                other_kpis = {
                                    "æ˜ç¡®åˆ°åº—": (p.get('S_Time'), "å»ºè®®ä½¿ç”¨äºŒé€‰ä¸€æ³•é”å®šæ—¶é—´ã€‚"),
                                    "æ·»åŠ å¾®ä¿¡": (p.get('S_Wechat'), "å»ºè®®ä»¥å‘å®šä½ä¸ºç”±åŠ å¾®ã€‚"),
                                    "ç”¨è½¦éœ€æ±‚": (p.get('S_Needs'), "éœ€åŠ å¼ºéœ€æ±‚æŒ–æ˜èƒ½åŠ›ã€‚"),
                                    "è½¦å‹ä¿¡æ¯": (p.get('S_Car'), "éœ€æå‡äº§å“DCCè¯æœ¯ç†Ÿç»ƒåº¦ã€‚"),
                                    "æ”¿ç­–ç›¸å…³": (p.get('S_Policy'), "éœ€å‡†ç¡®ä¼ è¾¾ä¿ƒé”€æ”¿ç­–åˆ©ç›Šç‚¹ã€‚")
                                }
                                cleaned_others = {}
                                for k, (v, advice) in other_kpis.items():
                                    cleaned_others[k] = (0 if pd.isna(v) else v, advice)

                                issues_list = []
                                is_failing = False
                                
                                if val_60s < 60:
                                    issues_list.append(f"ğŸŸ  **60ç§’å æ¯” (å¾—åˆ†{val_60s:.1f})**\nå¼€åœºç™½éœ€æŠ›å‡ºåˆ©ç›Šç‚¹ã€‚")
                                    is_failing = True
                                    
                                for k, (score, advice) in cleaned_others.items():
                                    if score < 80:
                                        issues_list.append(f"ğŸ”´ **{k} (å¾—åˆ†{score:.1f})**\n{advice}")
                                        is_failing = True
                                        
                                if is_failing:
                                    for item in issues_list: st.markdown(item)
                                    st.warning("âš ï¸ å­˜åœ¨æ˜æ˜¾çŸ­æ¿ï¼Œè¯·é‡ç‚¹è¾…å¯¼ã€‚")
                                else:
                                    all_above_85 = all(score >= 85 for score, _ in cleaned_others.values())
                                    if all_above_85: st.success("ğŸŒŸ **å„é¡¹æŒ‡æ ‡è¡¨ç°ä¼˜ç§€ï¼**")
                                    else: st.info("âœ… **å„é¡¹æŒ‡æ ‡åˆæ ¼**\nç›®å‰è¡¨ç°ç¨³å®šï¼Œä½†éƒ¨åˆ†æŒ‡æ ‡æœªè¾¾åˆ°85åˆ†å“è¶Šæ ‡å‡†ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚")
                            else: st.info("æš‚æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆè¯Šæ–­å»ºè®®ã€‚")
                else: st.warning("è¯¥é—¨åº—ä¸‹æš‚æ— æ•°æ®ã€‚")
else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Audi æ•ˆèƒ½çœ‹æ¿ï¼")
    st.warning("ğŸ‘‰ ç›®å‰æš‚æ— æ•°æ®ã€‚è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ å±•å¼€ã€æ›´æ–°æ•°æ®ã€‘ï¼Œè¾“å…¥ç®¡ç†å‘˜å¯†ç å¹¶ä¸Šä¼ æ‰€æœ‰ **4** ä¸ªæ•°æ®æ–‡ä»¶ã€‚")
