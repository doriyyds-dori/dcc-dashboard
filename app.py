import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from datetime import datetime

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")

st.markdown("""
<style>
    .top-container {display: flex; align-items: center; justify-content: space-between; padding-bottom: 20px; border-bottom: 2px solid #f0f0f0;}
    .metric-card {background-color: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    div[data-testid="stSelectbox"] {min-width: 200px;}
    .big-font {font-size: 18px !important; font-weight: bold;}
</style>
""", unsafe_allow_html=True)

# ================= 2. å®‰å…¨é”ä¸æ–‡ä»¶å­˜å‚¨ =================
ADMIN_PASSWORD = "AudiSARR3" 

DATA_DIR = "data_store"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)
PATH_F = os.path.join(DATA_DIR, "funnel.xlsx")      # 1. æ¼æ–—
PATH_D = os.path.join(DATA_DIR, "dcc.xlsx")         # 2. é¡¾é—®è´¨æ£€
PATH_A = os.path.join(DATA_DIR, "ams.xlsx")         # 3. AMS
PATH_S = os.path.join(DATA_DIR, "store_rank.csv")   # 4. é—¨åº—æ’å

def save_uploaded_file(uploaded_file, save_path):
    with open(save_path, "wb") as f: f.write(uploaded_file.getbuffer())
    return True

# ================= 3. ä¾§è¾¹æ é€»è¾‘ =================
with st.sidebar:
    st.header("âš™ï¸ ç®¡ç†é¢æ¿")
    # æ£€æŸ¥4ä¸ªæ–‡ä»¶æ˜¯å¦éƒ½å­˜åœ¨
    has_data = os.path.exists(PATH_F) and os.path.exists(PATH_D) and os.path.exists(PATH_A) and os.path.exists(PATH_S)
    
    if has_data: st.success("âœ… æ•°æ®çŠ¶æ€ï¼šå·²å°±ç»ª")
    else: st.warning("âš ï¸ æš‚æ— æ•°æ®")
    st.markdown("---")
    
    with st.expander("ğŸ” æ›´æ–°æ•°æ® (ä»…é™ç®¡ç†å‘˜)"):
        pwd = st.text_input("è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")
        if pwd == ADMIN_PASSWORD:
            st.info("ğŸ”“ è¯·ä¸Šä¼ æ–°æ–‡ä»¶ï¼š")
            new_f = st.file_uploader("1. æ¼æ–—æŒ‡æ ‡è¡¨", type=["xlsx", "csv"])
            new_d = st.file_uploader("2. é¡¾é—®è´¨æ£€è¡¨", type=["xlsx", "csv"])
            new_a = st.file_uploader("3. AMSè·Ÿè¿›è¡¨", type=["xlsx", "csv"])
            new_s = st.file_uploader("4. é—¨åº—æ’åè¡¨", type=["xlsx", "csv"]) 
            
            if st.button("ğŸš€ ç¡®è®¤æ›´æ–°æ•°æ®"):
                if new_f and new_d and new_a and new_s:
                    save_uploaded_file(new_f, PATH_F)
                    save_uploaded_file(new_d, PATH_D)
                    save_uploaded_file(new_a, PATH_A)
                    save_uploaded_file(new_s, PATH_S)
                    
                    st.success("æ•°æ®å·²ä¿å­˜ï¼æ­£åœ¨åˆ·æ–°çœ‹æ¿...")
                    st.rerun()
                else: st.error("è¯·ä¼ é½ 4 ä¸ªæ–‡ä»¶")

# ================= 4. æ•°æ®å¤„ç† =================
def smart_read(file_path, is_rank_file=False):
    """æ™ºèƒ½è¯»å–ï¼Œæ”¯æŒcsv/xlsxï¼Œé’ˆå¯¹æ’åè¡¨æ”¯æŒè·³è¿‡é¦–è¡Œ"""
    try:
        if isinstance(file_path, str):
            is_csv = file_path.endswith('.csv') or file_path.endswith('.txt')
        else:
            is_csv = file_path.name.endswith('.csv') or file_path.name.endswith('.txt')
            
        if is_csv:
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path)
            
        # é’ˆå¯¹é—¨åº—æ’åè¡¨çš„ç‰¹æ®Šå¤„ç†
        if is_rank_file:
            target_cols = ['é—¨åº—åç§°', 'è´¨æ£€æ€»åˆ†', 'æ’å']
            if not any(col in df.columns for col in target_cols):
                if is_csv: df = pd.read_csv(file_path, header=1)
                else: df = pd.read_excel(file_path, header=1)
        return df
    except: return None

def clean_percent_col(df, col_name):
    if col_name not in df.columns: return
    series = df[col_name].astype(str).str.strip().str.replace('%', '', regex=False)
    numeric_series = pd.to_numeric(series, errors='coerce').fillna(0)
    if numeric_series.max() > 1.0:
        df[col_name] = numeric_series / 100
    else:
        df[col_name] = numeric_series

def safe_div(df, num_col, denom_col):
    num = pd.to_numeric(df[num_col], errors='coerce').fillna(0)
    denom = pd.to_numeric(df[denom_col], errors='coerce').fillna(0)
    return (num / denom).replace([np.inf, -np.inf], 0).fillna(0)

def process_data(path_f, path_d, path_a, path_s):
    try:
        raw_f = smart_read(path_f)
        raw_d = smart_read(path_d)
        raw_a = smart_read(path_a)
        raw_s = smart_read(path_s, is_rank_file=True)
        
        if raw_f is None or raw_d is None or raw_a is None or raw_s is None: return None, None

        # ================= A. Funnel (æ¼æ–—) =================
        store_col = next((c for c in raw_f.columns if 'ä»£ç†å•†' in str(c) or 'é—¨åº—' in str(c)), raw_f.columns[0])
        name_col = next((c for c in raw_f.columns if 'ç®¡å®¶' in str(c) or 'é¡¾é—®' in str(c)), raw_f.columns[1])
        col_leads = 'çº¿ä¸Š_æœ‰æ•ˆçº¿ç´¢æ•°' if 'çº¿ä¸Š_æœ‰æ•ˆçº¿ç´¢æ•°' in raw_f.columns else 'çº¿ç´¢é‡'
        col_visits = 'çº¿ä¸Š_åˆ°åº—æ•°' if 'çº¿ä¸Š_åˆ°åº—æ•°' in raw_f.columns else 'åˆ°åº—é‡'
        col_excel_rate = next((c for c in raw_f.columns if 'ç‡' in str(c) and ('åˆ°åº—' in str(c) or 'æœ‰æ•ˆ' in str(c))), None)

        rename_dict = {store_col: 'é—¨åº—åç§°', name_col: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', col_leads: 'çº¿ç´¢é‡', col_visits: 'åˆ°åº—é‡'}
        if col_excel_rate: rename_dict[col_excel_rate] = 'Excel_Rate'
        
        df_f = raw_f.rename(columns=rename_dict)
        df_store_data = df_f[df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('å°è®¡', na=False)].copy()
        df_advisor_data = df_f[~df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('è®¡|-', na=False)].copy()

        for df in [df_store_data, df_advisor_data]:
            df['çº¿ç´¢é‡'] = pd.to_numeric(df['çº¿ç´¢é‡'], errors='coerce').fillna(0)
            df['åˆ°åº—é‡'] = pd.to_numeric(df['åˆ°åº—é‡'], errors='coerce').fillna(0)
            if 'Excel_Rate' in df.columns:
                clean_percent_col(df, 'Excel_Rate')
                df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = df['Excel_Rate']
            else:
                df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = safe_div(df, 'åˆ°åº—é‡', 'çº¿ç´¢é‡')
            df['çº¿ç´¢åˆ°åº—ç‡'] = (df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100).map('{:.1f}%'.format)

        # ================= B. DCC (é¡¾é—®è´¨æ£€) =================
        wechat_col = 'æ·»åŠ å¾®ä¿¡.1' if 'æ·»åŠ å¾®ä¿¡.1' in raw_d.columns else 'æ·»åŠ å¾®ä¿¡'
        df_d = raw_d.rename(columns={
            'é¡¾é—®åç§°': 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'è´¨æ£€æ€»åˆ†': 'è´¨æ£€æ€»åˆ†',
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        })
        df_d['S_Wechat'] = raw_d[wechat_col]
        
        score_cols = ['è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat', 'S_Time']
        for c in score_cols:
            df_d[c] = pd.to_numeric(df_d[c], errors='coerce') 
        df_d = df_d[['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] + score_cols]

        # ================= C. Store Scores (é—¨åº—è´¨æ£€) =================
        df_s = raw_s.rename(columns={
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        })
        s_wechat_col = 'æ·»åŠ å¾®ä¿¡.1' if 'æ·»åŠ å¾®ä¿¡.1' in raw_s.columns else 'æ·»åŠ å¾®ä¿¡'
        df_s['S_Wechat'] = raw_s[s_wechat_col]
        
        store_score_cols = ['é—¨åº—åç§°', 'è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat', 'S_Time']
        available_store_cols = [c for c in store_score_cols if c in df_s.columns]
        df_s = df_s[available_store_cols]
        for c in available_store_cols:
            if c != 'é—¨åº—åç§°':
                df_s[c] = pd.to_numeric(df_s[c], errors='coerce')

        # ================= D. AMS (è·Ÿè¿›æ•°æ®) =================
        cols_config = [
            ({'ç®¡å®¶å§“å'}, 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶'),
            ({'DCCå¹³å‡é€šè¯æ—¶é•¿'}, 'é€šè¯æ—¶é•¿'),
            ({'DCCæ¥é€šçº¿ç´¢æ•°'}, 'conn_num'), ({'DCCå¤–å‘¼çº¿ç´¢æ•°'}, 'conn_denom'),
            ({'DCCåŠæ—¶å¤„ç†çº¿ç´¢'}, 'timely_num'), ({'éœ€å¤–å‘¼çº¿ç´¢æ•°'}, 'timely_denom'),
            ({'äºŒæ¬¡å¤–å‘¼çº¿ç´¢æ•°'}, 'call2_num'), ({'éœ€å†å‘¼çº¿ç´¢æ•°'}, 'call2_denom'),
            ({'DCCä¸‰æ¬¡å¤–å‘¼çš„çº¿ç´¢æ•°', 'ä¸‰æ¬¡å¤–å‘¼çº¿ç´¢æ•°'}, 'call3_num'), 
            ({'DCCäºŒå‘¼çŠ¶æ€ä¸ºéœ€å†å‘¼çš„çº¿ç´¢æ•°', 'äºŒå‘¼çŠ¶æ€ä¸ºéœ€å†å‘¼'}, 'call3_denom')
        ]
        found_rename_map = {}
        for keywords, target_name in cols_config:
            found_col = None
            for col in raw_a.columns:
                for k in keywords:
                    if k in str(col).strip(): found_col = col; break
                if found_col: break
            if found_col: found_rename_map[found_col] = target_name
        
        df_a = raw_a.rename(columns=found_rename_map)
        
        all_ams_calc_cols = ['conn_num', 'conn_denom', 'timely_num', 'timely_denom', 
                             'call2_num', 'call2_denom', 'call3_num', 'call3_denom']
        for c in all_ams_calc_cols:
            if c not in df_a.columns: df_a[c] = 0
            else: df_a[c] = pd.to_numeric(df_a[c], errors='coerce').fillna(0)

        df_a['å¤–å‘¼æ¥é€šç‡'] = safe_div(df_a, 'conn_num', 'conn_denom')
        df_a['DCCåŠæ—¶å¤„ç†ç‡'] = safe_div(df_a, 'timely_num', 'timely_denom')
        df_a['DCCäºŒæ¬¡å¤–å‘¼ç‡'] = safe_div(df_a, 'call2_num', 'call2_denom')
        df_a['DCCä¸‰æ¬¡å¤–å‘¼ç‡'] = safe_div(df_a, 'call3_num', 'call3_denom')

        final_ams_cols = ['é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'é€šè¯æ—¶é•¿', 'å¤–å‘¼æ¥é€šç‡', 'DCCåŠæ—¶å¤„ç†ç‡', 'DCCäºŒæ¬¡å¤–å‘¼ç‡', 'DCCä¸‰æ¬¡å¤–å‘¼ç‡'] + all_ams_calc_cols
        df_a = df_a[final_ams_cols]

        # ================= E. Merge =================
        for df in [df_store_data, df_advisor_data, df_d, df_a, df_s]:
            if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' in df.columns: df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] = df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.strip()
            if 'é—¨åº—åç§°' in df.columns: df['é—¨åº—åç§°'] = df['é—¨åº—åç§°'].astype(str).str.strip()

        # 1. é¡¾é—®å…¨é‡è¡¨
        full_advisors = pd.merge(df_advisor_data, df_d, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        full_advisors = pd.merge(full_advisors, df_a, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        
        cols_to_fill_zero = ['çº¿ç´¢é‡', 'åˆ°åº—é‡', 'é€šè¯æ—¶é•¿'] + all_ams_calc_cols
        full_advisors[cols_to_fill_zero] = full_advisors[cols_to_fill_zero].fillna(0)

        # 2. é—¨åº—å…¨é‡è¡¨
        ams_agg_dict = {
            'conn_num': 'sum', 'conn_denom': 'sum',
            'timely_num': 'sum', 'timely_denom': 'sum',
            'call2_num': 'sum', 'call2_denom': 'sum',
            'call3_num': 'sum', 'call3_denom': 'sum'
        }
        store_ams = full_advisors.groupby('é—¨åº—åç§°').agg(ams_agg_dict).reset_index()
        
        store_ams['å¤–å‘¼æ¥é€šç‡'] = safe_div(store_ams, 'conn_num', 'conn_denom')
        store_ams['DCCåŠæ—¶å¤„ç†ç‡'] = safe_div(store_ams, 'timely_num', 'timely_denom')
        store_ams['DCCäºŒæ¬¡å¤–å‘¼ç‡'] = safe_div(store_ams, 'call2_num', 'call2_denom')
        store_ams['DCCä¸‰æ¬¡å¤–å‘¼ç‡'] = safe_div(store_ams, 'call3_num', 'call3_denom')

        full_stores = pd.merge(df_store_data, df_s, on='é—¨åº—åç§°', how='left')
        full_stores = pd.merge(full_stores, store_ams, on='é—¨åº—åç§°', how='left')
        
        return full_advisors, full_stores

    except Exception as e:
        st.error(f"å¤„ç†å‡ºé”™: {e}")
        return None, None

# ================= 5. ç•Œé¢æ¸²æŸ“ =================
if has_data:
    df_advisors, df_stores = process_data(PATH_F, PATH_D, PATH_A, PATH_S)
    
    if df_advisors is not None:
        
        col_header, col_filter = st.columns([3, 1])
        with col_header: st.title("Audi | DCC æ•ˆèƒ½çœ‹æ¿")
        with col_filter:
            if not df_stores.empty: all_stores = sorted(list(df_stores['é—¨åº—åç§°'].unique()))
            else: all_stores = sorted(list(df_advisors['é—¨åº—åç§°'].unique()))
            store_options = ["å…¨éƒ¨"] + all_stores
            selected_store = st.selectbox("ğŸ­ åˆ‡æ¢é—¨åº—è§†å›¾", store_options)

        if selected_store == "å…¨éƒ¨":
            current_df = df_stores.copy()
            current_df['åç§°'] = current_df['é—¨åº—åç§°']
            rank_title = "ğŸ† å…¨åŒºé—¨åº—æ’å"
            kpi_leads = current_df['çº¿ç´¢é‡'].sum()
            kpi_visits = current_df['åˆ°åº—é‡'].sum()
            kpi_rate = kpi_visits / kpi_leads if kpi_leads > 0 else 0
            kpi_score = current_df['è´¨æ£€æ€»åˆ†'].mean() 
        else:
            current_df = df_advisors[df_advisors['é—¨åº—åç§°'] == selected_store].copy()
            current_df['åç§°'] = current_df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶']
            rank_title = f"ğŸ‘¤ {selected_store} - é¡¾é—®æ’å"
            kpi_leads = current_df['çº¿ç´¢é‡'].sum()
            kpi_visits = current_df['åˆ°åº—é‡'].sum()
            kpi_rate = kpi_visits / kpi_leads if kpi_leads > 0 else 0
            kpi_score = current_df['è´¨æ£€æ€»åˆ†'].mean()

        # 1. Result
        st.subheader("1ï¸âƒ£ ç»“æœæ¦‚è§ˆ (Result)")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("æ€»æœ‰æ•ˆçº¿ç´¢", f"{int(kpi_leads):,}")
        k2.metric("æ€»å®é™…åˆ°åº—", f"{int(kpi_visits):,}")
        k3.metric("çº¿ç´¢åˆ°åº—ç‡", f"{kpi_rate:.1%}")
        k4.metric("å¹³å‡è´¨æ£€æ€»åˆ†", f"{kpi_score:.1f}")
        
        # 2. Process
        st.markdown("---")
        st.subheader("2ï¸âƒ£ DCC å¤–å‘¼è¿‡ç¨‹ç›‘æ§ (Process)")
        
        p1, p2, p3, p4 = st.columns(4)
        def calc_kpi_rate(df, num, denom):
            total_num = df[num].sum()
            total_denom = df[denom].sum()
            return total_num / total_denom if total_denom > 0 else 0

        avg_conn = calc_kpi_rate(current_df, 'conn_num', 'conn_denom')
        avg_timely = calc_kpi_rate(current_df, 'timely_num', 'timely_denom')
        avg_call2 = calc_kpi_rate(current_df, 'call2_num', 'call2_denom')
        avg_call3 = calc_kpi_rate(current_df, 'call3_num', 'call3_denom')
        
        p1.metric("ğŸ“ å¤–å‘¼æ¥é€šç‡", f"{avg_conn:.1%}")
        p2.metric("âš¡ DCCåŠæ—¶å¤„ç†ç‡", f"{avg_timely:.1%}")
        p3.metric("ğŸ”„ äºŒæ¬¡å¤–å‘¼ç‡", f"{avg_call2:.1%}")
        p4.metric("ğŸ” ä¸‰æ¬¡å¤–å‘¼ç‡", f"{avg_call3:.1%}")
        st.caption("æ³¨ï¼šä»¥ä¸Šä¸ºåŠ æƒå¹³å‡å€¼")

        # ç»˜å›¾æ•°æ®å‡†å¤‡
        plot_df_vis = current_df.copy()
        plot_df_vis['è´¨æ£€æ€»åˆ†_æ˜¾ç¤º'] = plot_df_vis['è´¨æ£€æ€»åˆ†'].fillna(0) 

        c_proc_1, c_proc_2 = st.columns(2)
        with c_proc_1:
            st.markdown("#### ğŸ•µï¸ å¼‚å¸¸ä¾¦æµ‹ï¼šDCCå¤–å‘¼æ¥é€šç‡ vs 60ç§’é€šè¯å æ¯”")
            st.info("ğŸ’¡ **åˆ†æé€»è¾‘ï¼š** å³ä¸‹è§’ï¼ˆæ¥é€šç‡é«˜ä½†60ç§’å æ¯”ä½ï¼‰ä»£è¡¨å¯èƒ½å­˜åœ¨â€œäººä¸ºå‹ä½æ—¶é•¿/è¯æœ¯å·®â€é—®é¢˜ã€‚")
            if 'S_60s' in plot_df_vis.columns:
                fig_p1 = px.scatter(
                    plot_df_vis, x="å¤–å‘¼æ¥é€šç‡", y="S_60s", size="çº¿ç´¢é‡", color="è´¨æ£€æ€»åˆ†_æ˜¾ç¤º",
                    hover_name="åç§°", labels={"å¤–å‘¼æ¥é€šç‡": "å¤–å‘¼æ¥é€šç‡", "S_60s": "60ç§’é€šè¯å æ¯”å¾—åˆ†"},
                    color_continuous_scale="RdYlGn", height=350
                )
                fig_p1.add_vline(x=avg_conn, line_dash="dash", line_color="gray")
                fig_p1.add_hline(y=plot_df_vis['S_60s'].mean(), line_dash="dash", line_color="gray")
                fig_p1.update_layout(xaxis=dict(tickformat=".0%"))
                fig_p1.update_traces(
                    customdata=np.stack((plot_df_vis['çº¿ç´¢é‡'], plot_df_vis['å¤–å‘¼æ¥é€šç‡'], plot_df_vis['S_60s'], plot_df_vis['è´¨æ£€æ€»åˆ†']), axis=-1),
                    hovertemplate=("<b>%{hovertext}</b><br><br>çº¿ç´¢é‡: %{customdata[0]:,}<br>å¤–å‘¼æ¥é€šç‡: %{customdata[1]:.1%}<br>60ç§’é€šè¯å æ¯”å¾—åˆ†: %{customdata[2]:.0f}<br>è´¨æ£€æ€»åˆ†: %{customdata[3]:.1f}<br><extra></extra>")
                )
                st.plotly_chart(fig_p1, use_container_width=True)
            else:
                st.warning("ç¼ºå°‘â€œ60ç§’é€šè¯â€æ•°æ®ï¼Œæ— æ³•ç»˜å›¾")

        with c_proc_2:
            st.markdown("#### ğŸ”— å½’å› åˆ†æï¼šè¿‡ç¨‹æŒ‡æ ‡ vs çº¿ç´¢é¦–é‚€åˆ°åº—ç‡")
            st.info("ğŸ’¡ **åˆ†æé€»è¾‘ï¼š** ç›‘æ§å¤–å‘¼åŠæ—¶æ€§ä¸é‚€çº¦åˆ°åº—ç‡ç›¸å…³æ€§ã€‚")
            x_axis_choice = st.radio("é€‰æ‹©æ¨ªè½´æŒ‡æ ‡ï¼š", ["DCCåŠæ—¶å¤„ç†ç‡", "DCCäºŒæ¬¡å¤–å‘¼ç‡", "DCCä¸‰æ¬¡å¤–å‘¼ç‡"], horizontal=True)
            plot_df_corr = plot_df_vis.copy()
            plot_df_corr['è½¬åŒ–ç‡%'] = plot_df_corr['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100
            fig_p2 = px.scatter(
                plot_df_corr, x=x_axis_choice, y="è½¬åŒ–ç‡%", size="çº¿ç´¢é‡", color="è´¨æ£€æ€»åˆ†_æ˜¾ç¤º",
                hover_name="åç§°", labels={x_axis_choice: x_axis_choice, "è½¬åŒ–ç‡%": "çº¿ç´¢åˆ°åº—ç‡(%)"},
                color_continuous_scale="Blues", height=300
            )
            fig_p2.update_layout(xaxis=dict(tickformat=".0%"))
            fig_p2.update_traces(
                customdata=np.stack((
                    plot_df_corr['çº¿ç´¢é‡'], plot_df_corr['DCCåŠæ—¶å¤„ç†ç‡'], plot_df_corr['DCCäºŒæ¬¡å¤–å‘¼ç‡'], 
                    plot_df_corr['DCCä¸‰æ¬¡å¤–å‘¼ç‡'], plot_df_corr['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'], plot_df_corr['è´¨æ£€æ€»åˆ†']
                ), axis=-1),
                hovertemplate=("<b>%{hovertext}</b><br><br>çº¿ç´¢é‡: %{customdata[0]:,}<br>DCCåŠæ—¶å¤„ç†ç‡: %{customdata[1]:.1%}<br>DCCäºŒæ¬¡å¤–å‘¼ç‡: %{customdata[2]:.1%}<br>DCCä¸‰æ¬¡å¤–å‘¼ç‡: %{customdata[3]:.1%}<br>çº¿ç´¢åˆ°åº—ç‡: %{customdata[4]:.1%}<br>è´¨æ£€æ€»åˆ†: %{customdata[5]:.1f}<br><extra></extra>")
            )
            st.plotly_chart(fig_p2, use_container_width=True)

        st.markdown("---")

        # 3. Rank & Diagnosis
        c_left, c_right = st.columns([1, 2])
        with c_left:
            st.markdown(f"### ğŸ† {rank_title}")
            rank_df = current_df[['åç§°', 'çº¿ç´¢åˆ°åº—ç‡', 'çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼', 'è´¨æ£€æ€»åˆ†']].copy()
            rank_df['Sort_Score'] = rank_df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'].fillna(-1)
            rank_df = rank_df.sort_values('Sort_Score', ascending=False).head(15)
            display_df = rank_df[['åç§°', 'çº¿ç´¢åˆ°åº—ç‡', 'è´¨æ£€æ€»åˆ†']]
            st.dataframe(
                display_df, hide_index=True, use_container_width=True, height=400,
                column_config={"åç§°": st.column_config.TextColumn("åç§°"), "çº¿ç´¢åˆ°åº—ç‡": st.column_config.TextColumn("çº¿ç´¢åˆ°åº—ç‡"), "è´¨æ£€æ€»åˆ†": st.column_config.NumberColumn("è´¨æ£€æ€»åˆ†", format="%.1f")}
            )

        with c_right:
            st.markdown("### ğŸ’¡ è¯æœ¯è´¨é‡ vs è½¬åŒ–ç»“æœ")
            if 'S_Time' in plot_df_vis.columns:
                plot_df = plot_df_vis.copy()
                plot_df['è½¬åŒ–ç‡%'] = plot_df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100
                fig = px.scatter(
                    plot_df, x="S_Time", y="è½¬åŒ–ç‡%", size="çº¿ç´¢é‡", color="è´¨æ£€æ€»åˆ†_æ˜¾ç¤º", hover_name="åç§°",
                    labels={"S_Time": "æ˜ç¡®åˆ°åº—æ—¶é—´å¾—åˆ†", "è½¬åŒ–ç‡%": "çº¿ç´¢åˆ°åº—ç‡(%)"}, color_continuous_scale="Reds", height=400
                )
                fig.update_traces(
                    customdata=np.stack((plot_df['çº¿ç´¢é‡'], plot_df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'], plot_df['è´¨æ£€æ€»åˆ†'], plot_df['S_Time']), axis=-1),
                    hovertemplate=("<b>%{hovertext}</b><br><br>çº¿ç´¢é‡: %{customdata[0]:,}<br>çº¿ç´¢åˆ°åº—ç‡: %{customdata[1]:.1%}<br>è´¨æ£€æ€»åˆ†: %{customdata[2]:.1f}<br>æ˜ç¡®åˆ°åº—æ—¶é—´å¾—åˆ†: %{customdata[3]:.1f}<extra></extra>")
                )
                if not plot_df.empty:
                    fig.add_vline(x=plot_df['S_Time'].mean(), line_dash="dash", line_color="gray")
                    fig.add_hline(y=kpi_rate * 100, line_dash="dash", line_color="gray")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("ç¼ºå°‘â€œæ˜ç¡®åˆ°åº—æ—¶é—´â€æ•°æ®ï¼Œæ— æ³•ç»˜å›¾")

        st.markdown("---")
        with st.container():
            st.markdown("### ğŸ•µï¸â€â™€ï¸ é‚€çº¦ä¸“å‘˜/ç®¡å®¶æ·±åº¦è¯Šæ–­")
            if selected_store == "å…¨éƒ¨":
                st.info("ğŸ’¡ è¯·å…ˆåœ¨å³ä¸Šæ–¹é€‰æ‹©å…·ä½“ã€é—¨åº—ã€‘ï¼ŒæŸ¥çœ‹è¯¥é—¨åº—ä¸‹çš„é¡¾é—®è¯¦ç»†è¯Šæ–­ã€‚")
            else:
                diag_df = current_df[current_df['çº¿ç´¢é‡'] > 0].copy()
                diag_list = sorted(diag_df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].unique())
                
                if len(diag_list) > 0:
                    selected_person = st.selectbox("ğŸ” é€‰æ‹©è¯¥åº—é‚€çº¦ä¸“å‘˜/ç®¡å®¶ï¼š", diag_list)
                    p = df_advisors[df_advisors['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] == selected_person].iloc[0]
                    
                    d1, d2, d3 = st.columns([1, 1, 1.2])
                    with d1:
                        st.caption("è½¬åŒ–æ¼æ–— (RESULT)")
                        fig_f = go.Figure(go.Funnel(
                            y = ["çº¿ç´¢é‡", "åˆ°åº—é‡"], x = [p['çº¿ç´¢é‡'], p['åˆ°åº—é‡']],
                            textinfo = "value+percent initial", marker = {"color": ["#d9d9d9", "#bb0a30"]}
                        ))
                        fig_f.update_layout(showlegend=False, height=180, margin=dict(t=0,b=0,l=0,r=0))
                        st.plotly_chart(fig_f, use_container_width=True)
                        st.metric("çº¿ç´¢åˆ°åº—ç‡", p['çº¿ç´¢åˆ°åº—ç‡']) 
                        st.caption(f"å¹³å‡é€šè¯æ—¶é•¿: {p['é€šè¯æ—¶é•¿']:.1f} ç§’")

                    has_score = not pd.isna(p['è´¨æ£€æ€»åˆ†']) and not pd.isna(p['S_Time'])

                    with d2:
                        st.caption("è´¨æ£€å¾—åˆ†è¯¦æƒ… (QUALITY)")
                        if has_score:
                            metrics = {"æ˜ç¡®åˆ°åº—æ—¶é—´": p['S_Time'], "60ç§’é€šè¯å æ¯”": p['S_60s'], "ç”¨è½¦éœ€æ±‚": p['S_Needs'], "è½¦å‹ä¿¡æ¯ä»‹ç»": p['S_Car'], "æ”¿ç­–ç›¸å…³è¯æœ¯": p['S_Policy'], "æ·»åŠ å¾®ä¿¡": p['S_Wechat']}
                            for k, v in metrics.items():
                                c_a, c_b = st.columns([3, 1])
                                val = 0 if pd.isna(v) else v
                                c_a.progress(min(val/100, 1.0))
                                c_b.write(f"{val:.1f}")
                                st.caption(k)
                        else: st.warning("æš‚æ— è´¨æ£€æ•°æ®")

                    with d3:
                        with st.container():
                            if has_score:
                                st.error("ğŸ¤– AI æ™ºèƒ½è¯Šæ–­å»ºè®®")
                                val_60s = 0 if pd.isna(p['S_60s']) else p['S_60s']
                                other_kpis = {
                                    "æ˜ç¡®åˆ°åº—": (p['S_Time'], "å»ºè®®ä½¿ç”¨äºŒé€‰ä¸€æ³•é”å®šæ—¶é—´ã€‚"),
                                    "æ·»åŠ å¾®ä¿¡": (p['S_Wechat'], "å»ºè®®ä»¥å‘å®šä½ä¸ºç”±åŠ å¾®ã€‚"),
                                    "ç”¨è½¦éœ€æ±‚": (p['S_Needs'], "éœ€åŠ å¼ºéœ€æ±‚æŒ–æ˜èƒ½åŠ›ã€‚"),
                                    "è½¦å‹ä¿¡æ¯": (p['S_Car'], "éœ€æå‡äº§å“DCCè¯æœ¯ç†Ÿç»ƒåº¦ã€‚"),
                                    "æ”¿ç­–ç›¸å…³": (p['S_Policy'], "éœ€å‡†ç¡®ä¼ è¾¾ä¿ƒé”€æ”¿ç­–åˆ©ç›Šç‚¹ã€‚")
                                }
                                cleaned_others = {}
                                for k, (v, advice) in other_kpis.items():
                                    cleaned_others[k] = (0 if pd.isna(v) else v, advice)

                                issues_list = []
                                is_failing = False
                                
                                if val_60s < 60:
                                    issues_list.append(f"ğŸŸ  **60ç§’å æ¯” (å¾—åˆ†{val_60s:.1f})**\nå¼€åœºç™½éœ€æŠ›å‡ºåˆ©ç›Šç‚¹ã€‚")
                                    is_failing = True
                                    
                                for k, (score, advice) in cleaned_others.items():
                                    if score < 80:
                                        issues_list.append(f"ğŸ”´ **{k} (å¾—åˆ†{score:.1f})**\n{advice}")
                                        is_failing = True
                                        
                                if is_failing:
                                    for item in issues_list: st.markdown(item)
                                    st.warning("âš ï¸ å­˜åœ¨æ˜æ˜¾çŸ­æ¿ï¼Œè¯·é‡ç‚¹è¾…å¯¼ã€‚")
                                else:
                                    all_above_85 = all(score >= 85 for score, _ in cleaned_others.values())
                                    if all_above_85: st.success("ğŸŒŸ **å„é¡¹æŒ‡æ ‡è¡¨ç°ä¼˜ç§€ï¼**")
                                    else: st.info("âœ… **å„é¡¹æŒ‡æ ‡åˆæ ¼**\nç›®å‰è¡¨ç°ç¨³å®šï¼Œä½†éƒ¨åˆ†æŒ‡æ ‡æœªè¾¾åˆ°85åˆ†å“è¶Šæ ‡å‡†ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚")
                            else: st.info("æš‚æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆè¯Šæ–­å»ºè®®ã€‚")
                else: st.warning("è¯¥é—¨åº—ä¸‹æš‚æ— æ•°æ®ã€‚")
else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Audi æ•ˆèƒ½çœ‹æ¿ï¼")
    st.warning("ğŸ‘‰ ç›®å‰æš‚æ— æ•°æ®ã€‚è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ å±•å¼€ã€æ›´æ–°æ•°æ®ã€‘ï¼Œè¾“å…¥ç®¡ç†å‘˜å¯†ç å¹¶ä¸Šä¼ æ‰€æœ‰ **4** ä¸ªæ•°æ®æ–‡ä»¶ã€‚")
