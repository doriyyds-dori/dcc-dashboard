import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from datetime import datetime

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")

st.markdown("""
<style>
    .metric-card {background-color: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    div[data-testid="stSelectbox"] {min-width: 200px;}
    div[data-testid="stFormSubmitButton"] button {
        width: 100%;
        background-color: #bb0a30;
        color: white;
        border: none;
        font-weight: bold;
    }
    div[data-testid="stFormSubmitButton"] button:hover {
        background-color: #990000;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# ================= 2. åŸºç¡€é…ç½® =================
ADMIN_PASSWORD = "AudiSARR3" 
DATA_DIR = "data_store"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# å†…éƒ¨æ–‡ä»¶ä»£å·æ˜ å°„ (ä¸éœ€è¦ç”¨æˆ·å…³å¿ƒæ–‡ä»¶åï¼Œä»£ç è‡ªåŠ¨å¤„ç†åç¼€)
FILE_KEYS = {
    "funnel": "1. æ¼æ–—è¡¨ (åŒ…å«: çº¿ç´¢é‡/åˆ°åº—é‡)",
    "dcc": "2. é¡¾é—®è´¨æ£€è¡¨ (åŒ…å«: é¡¾é—®å¾—åˆ†/ç®¡å®¶æ’å)",
    "ams": "3. AMSè¡¨ (åŒ…å«: æ¥é€šç‡/è·Ÿè¿›æ•°æ®)",
    "store_rank": "4. é—¨åº—æ’åè¡¨ (åŒ…å«: é—¨åº—å¾—åˆ†/æ’å)" 
}

def get_existing_file_path(base_name):
    """æ ¹æ®åŸºç¡€åæŸ¥æ‰¾å®é™…å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„ (è‡ªåŠ¨åˆ¤æ–­æ˜¯csvè¿˜æ˜¯xlsx)"""
    for ext in ['.xlsx', '.csv']:
        path = os.path.join(DATA_DIR, f"{base_name}{ext}")
        if os.path.exists(path):
            return path
    return None

def save_uploaded_file(uploaded_file, base_name):
    """ä¿å­˜æ–‡ä»¶ï¼Œè‡ªåŠ¨ä¿ç•™åŸå§‹åç¼€ï¼Œå¹¶åˆ é™¤æ—§çš„åŒåä¸åŒåç¼€æ–‡ä»¶"""
    try:
        # è·å–ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶çš„åç¼€ (.csv æˆ– .xlsx)
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        if file_ext not in ['.csv', '.xlsx']:
            file_ext = '.csv' # é»˜è®¤å›é€€
            
        save_path = os.path.join(DATA_DIR, f"{base_name}{file_ext}")
        
        # ä¸ºäº†é˜²æ­¢æ··æ·†ï¼Œå…ˆåˆ é™¤è¯¥åŸºç¡€åä¸‹çš„æ‰€æœ‰æ—§æ–‡ä»¶
        for ext in ['.xlsx', '.csv']:
            old_path = os.path.join(DATA_DIR, f"{base_name}{ext}")
            if os.path.exists(old_path):
                os.remove(old_path)
                
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        return True
    except Exception as e:
        st.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
        return False

# ================= 3. ä¾§è¾¹æ  =================
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Audi-Logo_2016.svg/1200px-Audi-Logo_2016.svg.png", width=150)
    st.header("âš™ï¸ ç®¡ç†é¢æ¿")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦é½å…¨
    missing_files = []
    for key in FILE_KEYS.keys():
        if not get_existing_file_path(key):
            missing_files.append(key)
    
    has_data = len(missing_files) == 0
    
    if has_data:
        st.success("âœ… æ•°æ®çŠ¶æ€ï¼šå·²å°±ç»ª")
    else:
        st.warning(f"âš ï¸ ç¼ºæ•°æ®ï¼Œè¯·ä¸Šä¼ ")
    st.markdown("---")
    
    with st.expander("ğŸ” æ›´æ–°æ•°æ® (ä»…é™ç®¡ç†å‘˜)", expanded=True):
        pwd = st.text_input("è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")
        
        if pwd == ADMIN_PASSWORD:
            st.info("ğŸ”“ èº«ä»½éªŒè¯é€šè¿‡")
            with st.form("data_update_form", clear_on_submit=False):
                st.markdown("##### è¯·å¯¹åº”ä¸Šä¼  4 ä¸ªæ–‡ä»¶ï¼š")
                
                # åŠ¨æ€ç”Ÿæˆä¸Šä¼ ç»„ä»¶
                up_f = st.file_uploader(FILE_KEYS['funnel'], type=["xlsx", "csv"])
                up_d = st.file_uploader(FILE_KEYS['dcc'], type=["xlsx", "csv"])
                up_a = st.file_uploader(FILE_KEYS['ams'], type=["xlsx", "csv"])
                up_s = st.file_uploader(FILE_KEYS['store_rank'], type=["xlsx", "csv"])
                
                if st.form_submit_button("ğŸš€ ç¡®è®¤å¹¶æ›´æ–°æ•°æ®"):
                    if up_f and up_d and up_a and up_s:
                        with st.spinner("æ­£åœ¨ä¿å­˜å¹¶å¤„ç†..."):
                            # ä½¿ç”¨å†…éƒ¨ä»£å·ä¿å­˜ï¼Œè‡ªåŠ¨è¯†åˆ«åç¼€
                            s1 = save_uploaded_file(up_f, "funnel")
                            s2 = save_uploaded_file(up_d, "dcc")
                            s3 = save_uploaded_file(up_a, "ams")
                            s4 = save_uploaded_file(up_s, "store_rank")
                            
                            if s1 and s2 and s3 and s4:
                                st.success("âœ… æ›´æ–°æˆåŠŸï¼æ­£åœ¨åˆ·æ–°é¡µé¢...")
                                st.rerun()
                    else:
                        st.error("âŒ è¯·ä¸€æ¬¡æ€§ä¸Šä¼ æ‰€æœ‰ 4 ä¸ªæ–‡ä»¶ï¼Œä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚")
        elif pwd:
            st.error("å¯†ç é”™è¯¯")

# ================= 4. æ•°æ®å¤„ç† =================
def smart_read(file_path):
    """
    å¢å¼ºç‰ˆæ–‡ä»¶è¯»å–ï¼šæ”¯æŒ xlsx å’Œ csv (utf-8/gbk)
    """
    try:
        if not file_path or not os.path.exists(file_path):
            return None
            
        df = None
        # 1. Excel å¤„ç†
        if file_path.endswith('.xlsx'):
            try:
                df = pd.read_excel(file_path, header=None)
            except Exception as e:
                st.error(f"Excelè¯»å–é”™è¯¯ {os.path.basename(file_path)}: {e}")
                return None
        else:
            # 2. CSV å¤šç¼–ç å°è¯•
            encodings = ['utf-8-sig', 'gb18030', 'utf-16']
            for enc in encodings:
                try:
                    df = pd.read_csv(file_path, header=None, encoding=enc, engine='python', on_bad_lines='skip')
                    break
                except: continue
            
            if df is None:
                st.error(f"âŒ æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç : {os.path.basename(file_path)}")
                return None

        # 3. æ™ºèƒ½å¯»æ‰¾è¡¨å¤´
        header_row = 0
        keywords = ['é—¨åº—', 'é¡¾é—®', 'ç®¡å®¶', 'æ’å', 'ä»£ç†å•†', 'åºå·', 'çº¿ç´¢']
        
        if len(df) > 0:
            for i in range(min(10, len(df))):
                row_values = df.iloc[i].astype(str).str.cat(sep=',')
                if any(k in row_values for k in keywords):
                    header_row = i
                    break
        
        df.columns = df.iloc[header_row]
        df = df[header_row + 1:].reset_index(drop=True)
        
        # æ¸…ç†åˆ—å
        df.columns = df.columns.astype(str).str.strip().str.replace('\n', '').str.replace('\r', '')
        # åˆ é™¤æ— ååˆ—
        df = df.loc[:, df.columns.notna()]
        
        return df

    except Exception as e:
        st.error(f"è¯»å–å¤±è´¥: {os.path.basename(file_path)} - {e}")
        return None

def safe_div(df, num_col, denom_col):
    if num_col not in df.columns or denom_col not in df.columns: return 0
    num = pd.to_numeric(df[num_col], errors='coerce').fillna(0)
    denom = pd.to_numeric(df[denom_col], errors='coerce').fillna(0)
    return (num / denom).replace([np.inf, -np.inf], 0).fillna(0)

@st.cache_data(ttl=300)
def process_data():
    # åŠ¨æ€è·å–æ–‡ä»¶è·¯å¾„
    path_f = get_existing_file_path("funnel")
    path_d = get_existing_file_path("dcc")
    path_a = get_existing_file_path("ams")
    path_s = get_existing_file_path("store_rank")
    
    try:
        raw_f = smart_read(path_f)
        raw_d = smart_read(path_d)
        raw_a = smart_read(path_a)
        raw_s = smart_read(path_s)
        
        if raw_f is None or raw_d is None or raw_a is None or raw_s is None: 
            return None, None

        # --- A. æ¼æ–—è¡¨å¤„ç† ---
        f_cols = raw_f.columns
        col_store = next((c for c in f_cols if 'é—¨åº—' in c or 'ä»£ç†' in c), 'é—¨åº—åç§°')
        col_name = next((c for c in f_cols if 'é¡¾é—®' in c or 'ç®¡å®¶' in c), 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶')
        col_leads = next((c for c in f_cols if 'æœ‰æ•ˆçº¿ç´¢' in c or 'çº¿ç´¢é‡' in c), 'çº¿ç´¢é‡')
        col_visits = next((c for c in f_cols if 'åˆ°åº—' in c and 'ç‡' not in c), 'åˆ°åº—é‡')
        
        df_f = raw_f.rename(columns={col_store: 'é—¨åº—åç§°', col_name: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', col_leads: 'çº¿ç´¢é‡', col_visits: 'åˆ°åº—é‡'})
        
        mask_sub = df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('å°è®¡', na=False)
        df_store_data = df_f[mask_sub].copy()
        df_advisor_data = df_f[~mask_sub].copy()

        for df in [df_store_data, df_advisor_data]:
            df['çº¿ç´¢é‡'] = pd.to_numeric(df['çº¿ç´¢é‡'], errors='coerce').fillna(0)
            df['åˆ°åº—é‡'] = pd.to_numeric(df['åˆ°åº—é‡'], errors='coerce').fillna(0)
            df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = safe_div(df, 'åˆ°åº—é‡', 'çº¿ç´¢é‡')
            df['çº¿ç´¢åˆ°åº—ç‡'] = (df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100).map('{:.1f}%'.format)

        # --- B. é¡¾é—®è´¨æ£€è¡¨ ---
        d_map = {
            'é¡¾é—®åç§°': 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'è´¨æ£€æ€»åˆ†': 'è´¨æ£€æ€»åˆ†',
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        }
        wechat_raw = next((c for c in raw_d.columns if 'å¾®ä¿¡' in c and 'æ·»åŠ ' in c), 'æ·»åŠ å¾®ä¿¡')
        df_d = raw_d.rename(columns=d_map)
        df_d['S_Wechat'] = df_d[wechat_raw] if wechat_raw in df_d.columns else 0
        
        num_cols = ['è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Time', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat']
        for c in num_cols: 
            if c in df_d.columns: df_d[c] = pd.to_numeric(df_d[c], errors='coerce')
        
        if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' not in df_d.columns and 'ç®¡å®¶' in raw_d.columns:
            df_d.rename(columns={'ç®¡å®¶': 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶'}, inplace=True)

        # --- C. é—¨åº—æ’åè¡¨ ---
        s_map = {
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        }
        s_wechat_raw = next((c for c in raw_s.columns if 'å¾®ä¿¡' in c and 'æ·»åŠ ' in c), 'æ·»åŠ å¾®ä¿¡')
        s_store_raw = next((c for c in raw_s.columns if 'é—¨åº—' in c and 'ID' not in c), 'é—¨åº—åç§°')
        
        df_s = raw_s.rename(columns={**s_map, s_store_raw: 'é—¨åº—åç§°'})
        df_s['S_Wechat'] = df_s[s_wechat_raw] if s_wechat_raw in df_s.columns else 0
        
        for c in ['è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Time']:
            if c in df_s.columns: df_s[c] = pd.to_numeric(df_s[c], errors='coerce')

        # --- D. AMSè¡¨ ---
        a_map = {}
        for c in raw_a.columns:
            if 'æ¥é€š' in c and 'çº¿ç´¢' in c and 'ç‡' not in c: a_map[c] = 'conn_num'
            if 'å¤–å‘¼' in c and 'çº¿ç´¢' in c and 'éœ€' not in c and 'ç‡' not in c: a_map[c] = 'conn_denom'
            if 'ç®¡å®¶' in c or 'é¡¾é—®' in c: a_map[c] = 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶'
            if 'å¹³å‡é€šè¯æ—¶é•¿' in c: a_map[c] = 'é€šè¯æ—¶é•¿'
            
        df_a = raw_a.rename(columns=a_map)
        
        for c in ['conn_num', 'conn_denom', 'é€šè¯æ—¶é•¿']:
            if c not in df_a.columns: df_a[c] = 0
            else: df_a[c] = pd.to_numeric(df_a[c], errors='coerce').fillna(0)

        # --- E. åˆå¹¶ ---
        for df in [df_advisor_data, df_d, df_a, df_store_data, df_s]:
            if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' in df.columns:
                df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] = df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.strip()
            if 'é—¨åº—åç§°' in df.columns:
                df['é—¨åº—åç§°'] = df['é—¨åº—åç§°'].astype(str).str.strip()

        # 1. é¡¾é—®å±‚åˆå¹¶
        full_advisors = pd.merge(df_advisor_data, df_d, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' in df_a.columns:
            df_a_unique = df_a.groupby('é‚€çº¦ä¸“å‘˜/ç®¡å®¶').first().reset_index()
            full_advisors = pd.merge(full_advisors, df_a_unique, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        
        # 2. é—¨åº—å±‚åˆå¹¶
        if 'conn_num' in full_advisors.columns and 'é—¨åº—åç§°' in full_advisors.columns:
            ams_grp = full_advisors.groupby('é—¨åº—åç§°')[['conn_num', 'conn_denom']].sum().reset_index()
        else:
            ams_grp = pd.DataFrame(columns=['é—¨åº—åç§°', 'conn_num', 'conn_denom'])

        full_stores = pd.merge(df_store_data, df_s, on='é—¨åº—åç§°', how='left')
        full_stores = pd.merge(full_stores, ams_grp, on='é—¨åº—åç§°', how='left')
        
        return full_advisors, full_stores

    except Exception as e:
        import traceback
        st.error(f"æ•°æ®å¤„ç†é€»è¾‘é”™è¯¯: {e}")
        st.text(traceback.format_exc())
        return None, None

# ================= 5. ç•Œé¢æ¸²æŸ“ =================
if has_data:
    df_advisors, df_stores = process_data()
    
    if df_advisors is not None:
        
        st.sidebar.markdown("---")
        if not df_stores.empty:
            store_options = ["å…¨éƒ¨"] + sorted(list(df_stores['é—¨åº—åç§°'].unique()))
        else:
            store_options = ["å…¨éƒ¨"]
            
        selected_store = st.sidebar.selectbox("ğŸ­ åˆ‡æ¢é—¨åº—è§†å›¾", store_options)

        if selected_store == "å…¨éƒ¨":
            current_df = df_stores.copy()
            current_df['Name'] = current_df['é—¨åº—åç§°']
            rank_title = "ğŸ† å…¨åŒºé—¨åº—æ’å"
        else:
            current_df = df_advisors[df_advisors['é—¨åº—åç§°'] == selected_store].copy()
            current_df['Name'] = current_df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶']
            rank_title = f"ğŸ‘¤ {selected_store} - é¡¾é—®æ’å"

        # KPI
        kpi_leads = current_df['çº¿ç´¢é‡'].sum()
        kpi_visits = current_df['åˆ°åº—é‡'].sum()
        kpi_rate = kpi_visits / kpi_leads if kpi_leads > 0 else 0
        kpi_score = current_df['è´¨æ£€æ€»åˆ†'].mean() if 'è´¨æ£€æ€»åˆ†' in current_df.columns else 0

        # 1. æ¦‚è§ˆ
        st.subheader("1ï¸âƒ£ ç»“æœæ¦‚è§ˆ (Result)")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("æ€»æœ‰æ•ˆçº¿ç´¢", f"{int(kpi_leads):,}")
        k2.metric("æ€»å®é™…åˆ°åº—", f"{int(kpi_visits):,}")
        k3.metric("çº¿ç´¢åˆ°åº—ç‡", f"{kpi_rate:.1%}")
        k4.metric("å¹³å‡è´¨æ£€æ€»åˆ†", f"{kpi_score:.1f}")
        
        st.markdown("---")

        # 2. å›¾è¡¨
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("é€šè¯è´¨é‡åˆ†æ")
            if 'S_60s' in current_df.columns and 'conn_num' in current_df.columns:
                current_df['æ¥é€šç‡'] = safe_div(current_df, 'conn_num', 'conn_denom')
                plot_df = current_df.fillna(0)
                fig = px.scatter(
                    plot_df, x="æ¥é€šç‡", y="S_60s", size="çº¿ç´¢é‡", 
                    color="è´¨æ£€æ€»åˆ†" if 'è´¨æ£€æ€»åˆ†' in plot_df.columns else None,
                    hover_name="Name",
                    labels={'S_60s': '60ç§’é€šè¯å æ¯”', 'æ¥é€šç‡': 'å¤–å‘¼æ¥é€šç‡'}
                )
                fig.update_layout(xaxis_tickformat=".0%", height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("â„¹ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ˜¾ç¤ºé€šè¯è´¨é‡æ•£ç‚¹å›¾ (éœ€ AMS å’Œ è´¨æ£€æ•°æ®)")

        with c2:
            st.subheader(rank_title)
            show_cols = ['Name', 'çº¿ç´¢åˆ°åº—ç‡', 'è´¨æ£€æ€»åˆ†', 'çº¿ç´¢é‡', 'åˆ°åº—é‡']
            if 'S_60s' in current_df.columns: show_cols.append('S_60s')
            show_cols = [c for c in show_cols if c in current_df.columns]
            
            if not current_df.empty:
                st.dataframe(
                    current_df[show_cols].sort_values('çº¿ç´¢é‡', ascending=False),
                    use_container_width=True, height=400, hide_index=True
                )
            else:
                st.warning("æš‚æ— æ•°æ®")
else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼è¯·åœ¨å·¦ä¾§ç‚¹å‡»â€œæ›´æ–°æ•°æ®â€å¹¶ä¸Šä¼ æ–‡ä»¶ã€‚")
