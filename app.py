import streamlit as st
import pandas as pd
import plotly.express as px
import os
import io

# ================= 1. åŸºç¡€é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")
DATA_DIR = "data_store"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)

# æ¸…ç†æ—§æ–‡ä»¶
def clear_old_files():
    import glob
    for f in glob.glob(os.path.join(DATA_DIR, "*")):
        try: os.remove(f)
        except: pass

# ================= 2. å¤–ç§‘æ‰‹æœ¯å¼è¯»å–å‡½æ•° (æ ¸å¿ƒä¿®å¤) =================
def surgical_read(file_path, file_desc):
    """
    é’ˆå¯¹ "Ragged CSV" (åˆ—æ•°ä¸é½) çš„ç»ˆæä¿®å¤ï¼š
    å…ˆä½œä¸ºçº¯æ–‡æœ¬è¯»å– -> æ‰¾åˆ°çœŸæ­£çš„è¡¨å¤´è¡Œ -> æˆªå–æœ‰æ•ˆå†…å®¹ -> ç”Ÿæˆ DataFrame
    """
    try:
        # 1. å¦‚æœæ˜¯ Excel (.xlsx)ï¼Œç›´æ¥ç”¨æ ‡å‡†è¯»å–
        if file_path.endswith('.xlsx'):
            return pd.read_excel(file_path, header=0) # é»˜è®¤è¯»ç¬¬1è¡Œï¼Œå¦‚æœå¤±è´¥åé¢ä¼šæœ‰é€»è¾‘ä¿®æ­£

        # 2. å¦‚æœæ˜¯ CSVï¼Œè¿›è¡Œå¤–ç§‘æ‰‹æœ¯å¤„ç†
        content = None
        used_encoding = 'utf-8'
        
        # å°è¯•è§£ç  (åŒ…å«ä¸­æ–‡çš„ CSV é€šå¸¸æ˜¯ GBK æˆ– UTF-8-SIG)
        for enc in ['utf-8-sig', 'gb18030', 'gbk', 'utf-8']:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    content = f.readlines()
                used_encoding = enc
                break
            except:
                continue
        
        if content is None:
            st.error(f"âŒ {file_desc} ç¼–ç è¯†åˆ«å¤±è´¥ï¼Œæ— æ³•è¯»å–ã€‚")
            return None

        # 3. å¯»æ‰¾â€œçœŸè¡¨å¤´â€æ‰€åœ¨çš„è¡Œæ•°
        # æ‚¨çš„æ–‡ä»¶ä¸­ï¼ŒçœŸæ­£æœ‰ç”¨çš„é‚£ä¸€è¡ŒåŒ…å« "é—¨åº—åç§°", "æ’å", "è´¨æ£€æ€»åˆ†" ç­‰å…³é”®è¯
        # ç¬¬ä¸€è¡Œé‚£äº› ",,,,,æµç¨‹è§„èŒƒ" æ˜¯å¹²æ‰°é¡¹
        
        keywords = ['é—¨åº—åç§°', 'é¡¾é—®', 'ç®¡å®¶', 'çº¿ç´¢', 'æ’å']
        start_row = -1
        
        for i, line in enumerate(content[:20]): # åªæ‰«å‰20è¡Œ
            if any(k in line for k in keywords):
                start_row = i
                break
        
        if start_row == -1:
            # å¦‚æœæ²¡æ‰¾åˆ°å…³é”®è¯ï¼Œå°è¯•ç›´æ¥æš´åŠ›è¯»å–
            st.warning(f"âš ï¸ {file_desc} æœªæ‰¾åˆ°æ˜æ˜¾è¡¨å¤´ï¼Œå°è¯•å¼ºè¡Œè¯»å–...")
            return pd.read_csv(file_path, encoding=used_encoding)

        # 4. æˆªå–æœ‰æ•ˆéƒ¨åˆ†å¹¶ç”Ÿæˆ DataFrame
        # å°† list of strings é‡æ–°ç»„åˆæˆå•ä¸ª string IO å¯¹è±¡
        clean_content = "".join(content[start_row:])
        df = pd.read_csv(io.StringIO(clean_content))
        
        # æ¸…ç†åˆ—åä¸­çš„å›è½¦æ¢è¡Œ
        df.columns = df.columns.astype(str).str.strip().str.replace('\n', '')
        
        return df

    except Exception as e:
        st.error(f"âŒ è¯»å– {file_desc} å‘ç”Ÿé”™è¯¯: {e}")
        return None

# ================= 3. æ•°æ®å¤„ç† =================
def process_data_logic():
    # æ‰«æç›®å½•ä¸‹æ–‡ä»¶
    files = [f for f in os.listdir(DATA_DIR) if not f.startswith('.')]
    
    data_map = {"funnel": None, "dcc": None, "ams": None, "rank": None}
    
    for f in files:
        full_path = os.path.join(DATA_DIR, f)
        
        # æ— è®ºåç¼€æ˜¯ä»€ä¹ˆï¼Œå…ˆè¯»è¿›æ¥çœ‹çœ‹åˆ—å
        df = surgical_read(full_path, f)
        
        if df is not None:
            cols = list(df.columns)
            # æ™ºèƒ½åˆ†ç±»
            if 'åˆ°åº—é‡' in cols or 'æœ‰æ•ˆçº¿ç´¢' in cols:
                data_map['funnel'] = df
            elif 'æ’å' in cols and 'é—¨åº—åç§°' in cols:
                data_map['rank'] = df
            elif ('60ç§’é€šè¯' in cols or 'S_60s' in cols) and 'è´¨æ£€æ€»åˆ†' in cols:
                data_map['dcc'] = df
            elif 'å¤–å‘¼çº¿ç´¢æ•°' in cols or 'æ¥é€šçº¿ç´¢æ•°' in cols:
                data_map['ams'] = df
    
    return data_map

# ================= 4. ç•Œé¢æ¸²æŸ“ =================
st.sidebar.header("ğŸ› ï¸ æ•°æ®ä¸Šä¼ ")

with st.sidebar.form("upload_panel"):
    st.write("è¯·ç›´æ¥ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶ (åŸå§‹æ ¼å¼å³å¯)ï¼š")
    uploaded_files = st.file_uploader("", accept_multiple_files=True)
    if st.form_submit_button("å¼€å§‹åˆ†æ"):
        if uploaded_files:
            clear_old_files()
            for f in uploaded_files:
                save_path = os.path.join(DATA_DIR, f.name)
                with open(save_path, "wb") as buffer:
                    buffer.write(f.getbuffer())
            st.success(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼")
            st.rerun()

# æ ¸å¿ƒé€»è¾‘
data_map = process_data_logic()
missing_files = [k for k, v in data_map.items() if v is None]

if not missing_files:
    try:
        # === æ•°æ®å‡†å¤‡ ===
        df_f = data_map['funnel']
        df_d = data_map['dcc']
        df_a = data_map['ams']
        df_s = data_map['rank']

        # 1. ç»Ÿä¸€åˆ—åæ˜ å°„
        def standardize_cols(df):
            new_cols = {}
            for c in df.columns:
                if 'é—¨åº—' in c: new_cols[c] = 'é—¨åº—åç§°'
                elif 'é¡¾é—®' in c or 'ç®¡å®¶' in c: new_cols[c] = 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶'
                elif 'æœ‰æ•ˆçº¿ç´¢' in c or 'çº¿ç´¢é‡' in c: new_cols[c] = 'çº¿ç´¢é‡'
                elif 'åˆ°åº—' in c and 'ç‡' not in c: new_cols[c] = 'åˆ°åº—é‡'
                elif 'æ¥é€š' in c and 'çº¿ç´¢' in c: new_cols[c] = 'conn_num'
                elif 'å¤–å‘¼' in c and 'çº¿ç´¢' in c: new_cols[c] = 'conn_denom'
            df.rename(columns=new_cols, inplace=True)
            return df

        df_f = standardize_cols(df_f)
        df_d = standardize_cols(df_d)
        df_a = standardize_cols(df_a)
        df_s = standardize_cols(df_s)

        # 2. æ•°å€¼è½¬æ¢å·¥å…·
        def to_num(series):
            return pd.to_numeric(series, errors='coerce').fillna(0)

        # 3. å¤„ç†æ¼æ–—è¡¨
        df_f['çº¿ç´¢é‡'] = to_num(df_f['çº¿ç´¢é‡'])
        df_f['åˆ°åº—é‡'] = to_num(df_f['åˆ°åº—é‡'])
        
        # æ‹†åˆ†
        if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' in df_f.columns:
            mask_sub = df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('å°è®¡', na=False)
            df_store_base = df_f[mask_sub].copy()
            df_advisor_base = df_f[~mask_sub].copy()
        else:
            df_store_base = df_f.copy()
            df_advisor_base = pd.DataFrame()

        # 4. åˆå¹¶é¡¾é—®æ•°æ®
        full_advisors = df_advisor_base
        if not full_advisors.empty:
            full_advisors = pd.merge(full_advisors, df_d, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
            if 'conn_num' in df_a.columns:
                full_advisors = pd.merge(full_advisors, df_a, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
                full_advisors['conn_num'] = to_num(full_advisors['conn_num'])
                full_advisors['conn_denom'] = to_num(full_advisors['conn_denom'])

        # 5. åˆå¹¶é—¨åº—æ•°æ® (æ¼æ–— + æ’åè¡¨)
        # æ’åè¡¨é‡Œåº”è¯¥å·²ç»æœ‰ 'è´¨æ£€æ€»åˆ†', '60ç§’é€šè¯' ç­‰
        full_stores = pd.merge(df_store_base, df_s, on='é—¨åº—åç§°', how='left')
        
        # æ¸…æ´—æœ€ç»ˆæ•°æ®
        full_stores['è´¨æ£€æ€»åˆ†'] = to_num(full_stores.get('è´¨æ£€æ€»åˆ†', 0))
        
        # å°è¯•æ‰¾ 60ç§’é€šè¯ åˆ— (å¯èƒ½å« 60ç§’é€šè¯ æˆ– S_60s)
        s_60_col = next((c for c in full_stores.columns if '60' in str(c)), None)
        if s_60_col: full_stores['S_60s'] = to_num(full_stores[s_60_col])
        else: full_stores['S_60s'] = 0

        # === é¡µé¢å±•ç¤º ===
        st.title("ğŸ“Š Audi DCC æ•ˆèƒ½çœ‹æ¿")
        
        tab1, tab2 = st.tabs(["ğŸ† å…¨åŒºæ¦‚è§ˆ", "ğŸ‘¤ é¡¾é—®è¯¦æƒ…"])
        
        with tab1:
            k1, k2, k3 = st.columns(3)
            k1.metric("å…¨åŒºæ€»çº¿ç´¢", int(full_stores['çº¿ç´¢é‡'].sum()))
            k2.metric("å…¨åŒºæ€»åˆ°åº—", int(full_stores['åˆ°åº—é‡'].sum()))
            
            avg_score = full_stores[full_stores['è´¨æ£€æ€»åˆ†']>0]['è´¨æ£€æ€»åˆ†'].mean()
            k3.metric("é—¨åº—å¹³å‡è´¨æ£€åˆ†", f"{avg_score:.1f}")
            
            st.markdown("### é—¨åº—æ’åæ¦œ")
            
            # å±•ç¤ºåˆ—
            cols = ['é—¨åº—åç§°', 'çº¿ç´¢é‡', 'åˆ°åº—é‡', 'è´¨æ£€æ€»åˆ†', 'S_60s']
            cols = [c for c in cols if c in full_stores.columns]
            
            # å¢åŠ åˆ°åº—ç‡
            full_stores['çº¿ç´¢åˆ°åº—ç‡'] = (full_stores['åˆ°åº—é‡'] / full_stores['çº¿ç´¢é‡'].replace(0, 1)).apply(lambda x: f"{x:.1%}")
            cols.insert(3, 'çº¿ç´¢åˆ°åº—ç‡')
            
            st.dataframe(
                full_stores[cols].sort_values('è´¨æ£€æ€»åˆ†', ascending=False),
                use_container_width=True,
                height=500
            )

        with tab2:
            if not full_advisors.empty:
                st.markdown("### é¡¾é—®æ˜ç»†æ•°æ®")
                stores = ["å…¨éƒ¨"] + list(full_advisors['é—¨åº—åç§°'].unique())
                sel = st.selectbox("ç­›é€‰é—¨åº—", stores)
                
                view_df = full_advisors if sel == "å…¨éƒ¨" else full_advisors[full_advisors['é—¨åº—åç§°']==sel]
                
                # è®¡ç®—å±•ç¤ºå­—æ®µ
                view_df['çº¿ç´¢åˆ°åº—ç‡'] = (view_df['åˆ°åº—é‡'] / view_df['çº¿ç´¢é‡'].replace(0, 1)).apply(lambda x: f"{x:.1%}")
                
                # å°è¯•æ‰¾æ¥é€šç‡
                if 'conn_num' in view_df.columns:
                    view_df['æ¥é€šç‡'] = (view_df['conn_num'] / view_df['conn_denom'].replace(0, 1))
                    
                    # æ°”æ³¡å›¾
                    # æ‰¾ 60ç§’ åˆ—
                    adv_60_col = next((c for c in view_df.columns if '60' in str(c)), None)
                    if adv_60_col:
                        view_df[adv_60_col] = to_num(view_df[adv_60_col])
                        view_df['è´¨æ£€æ€»åˆ†'] = to_num(view_df.get('è´¨æ£€æ€»åˆ†', 0))
                        
                        fig = px.scatter(
                            view_df, x='æ¥é€šç‡', y=adv_60_col, 
                            size='çº¿ç´¢é‡', color='è´¨æ£€æ€»åˆ†', 
                            hover_name='é‚€çº¦ä¸“å‘˜/ç®¡å®¶',
                            title="è¯æœ¯æ‰§è¡Œ(Y) vs æ¥é€šæ•ˆç‡(X)"
                        )
                        fig.update_layout(xaxis_tickformat=".0%")
                        st.plotly_chart(fig, use_container_width=True)
                
                st.dataframe(view_df, use_container_width=True)
            else:
                st.info("æš‚æ— é¡¾é—®å±‚çº§æ•°æ®")

    except Exception as e:
        st.error(f"æ•°æ®å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        st.code(traceback.format_exc())

else:
    st.info("ğŸ‘‹ è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    st.write("æ–‡ä»¶è¯†åˆ«çŠ¶æ€ï¼š")
    cols = st.columns(4)
    labels = ["æ¼æ–—è¡¨", "é¡¾é—®è´¨æ£€", "AMSè¡¨", "é—¨åº—æ’å"]
    keys = ["funnel", "dcc", "ams", "rank"]
    
    for i in range(4):
        status = "âœ…" if data_map[keys[i]] is not None else "âŒ"
        cols[i].metric(labels[i], status)
