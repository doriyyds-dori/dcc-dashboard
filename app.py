import streamlit as st
import pandas as pd
import plotly.express as px
import os
import glob

# ================= 1. åŸºç¡€é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿ (æœ€ç»ˆä¿®å¤ç‰ˆ)", layout="wide", page_icon="ğŸ› ï¸")
DATA_DIR = "data_store"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)

# æ¸…ç†æ—§æ–‡ä»¶ï¼ˆé˜²æ­¢å¹²æ‰°ï¼‰
def clear_old_files():
    files = glob.glob(os.path.join(DATA_DIR, "*"))
    for f in files:
        try: os.remove(f)
        except: pass

# ================= 2. æ™ºèƒ½è¯»å–æ ¸å¿ƒå‡½æ•° =================
def find_header_and_read(file_path):
    """
    ä¸ç®¡è¡¨å¤´åœ¨å“ªé‡Œï¼Œæš´åŠ›æ‰¾åˆ°å®ƒã€‚
    """
    try:
        # 1. å°è¯•è¯»å–ï¼ˆè‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼‰
        if file_path.endswith('.csv'):
            try:
                # ä¼˜å…ˆå°è¯• GBK (ä¸­æ–‡å¸¸è§)ï¼Œå¤±è´¥åˆ™ UTF-8
                df_raw = pd.read_csv(file_path, header=None, encoding='gb18030')
            except:
                df_raw = pd.read_csv(file_path, header=None, encoding='utf-8')
        else:
            df_raw = pd.read_excel(file_path, header=None)
        
        # 2. æš´åŠ›æœå¯»è¡¨å¤´è¡Œ
        # æˆ‘ä»¬è¦æ‰¾çš„å…³é”®è¯
        target_keywords = ['é—¨åº—åç§°', 'é¡¾é—®', 'ç®¡å®¶', 'çº¿ç´¢', 'æ’å', 'æ¥é€š', 'è´¨æ£€æ€»åˆ†']
        
        header_row_index = -1
        
        # æ‰«æå‰ 10 è¡Œ
        for i in range(min(10, len(df_raw))):
            row_str = df_raw.iloc[i].astype(str).str.cat(sep=' ')
            # å¦‚æœè¿™ä¸€è¡ŒåŒ…å«ä»»æ„ä¸€ä¸ªå…³é”®è¯
            if any(k in row_str for k in target_keywords):
                header_row_index = i
                break
        
        if header_row_index == -1:
            return None, "æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¡¨å¤´ï¼ˆåŒ…å«'é—¨åº—'ã€'é¡¾é—®'ç­‰å­—æ ·ï¼‰"

        # 3. é‡å¡‘ Dataframe
        df = df_raw.iloc[header_row_index+1:].copy()
        df.columns = df_raw.iloc[header_row_index].astype(str).str.strip().str.replace('\n', '')
        df.reset_index(drop=True, inplace=True)
        
        return df, "Success"

    except Exception as e:
        return None, str(e)

# ================= 3. æ•°æ®å¤„ç† =================
def process_all_files():
    # è·å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶
    all_files = os.listdir(DATA_DIR)
    
    # è‡ªåŠ¨å½’ç±»æ–‡ä»¶
    file_map = {"funnel": None, "dcc": None, "ams": None, "rank": None}
    
    for f in all_files:
        full_path = os.path.join(DATA_DIR, f)
        if f.startswith("."): continue # è·³è¿‡éšè—æ–‡ä»¶
        
        # è¯»å–å†…å®¹åˆ¤æ–­ç±»å‹
        df, msg = find_header_and_read(full_path)
        if df is None: continue
        
        cols = list(df.columns)
        # æ ¹æ®åˆ—åç‰¹å¾åˆ¤æ–­æ˜¯å“ªä¸ªè¡¨
        if 'åˆ°åº—é‡' in cols or 'æœ‰æ•ˆçº¿ç´¢' in cols:
            file_map["funnel"] = df
        elif '60ç§’é€šè¯' in cols and 'è´¨æ£€æ€»åˆ†' in cols and 'é—¨åº—åç§°' in cols:
            # é—¨åº—æ’åè¡¨é€šå¸¸ä¹Ÿæœ‰è´¨æ£€åˆ†ï¼Œä¸”å¿…é¡»æœ‰é—¨åº—åç§°
            file_map["rank"] = df
        elif '60ç§’é€šè¯' in cols and 'è´¨æ£€æ€»åˆ†' in cols:
            # é¡¾é—®è¡¨é€šå¸¸ä¹Ÿæœ‰è¿™äº›ï¼Œä½†æ²¡æœ‰â€œæ’åâ€åˆ—
            file_map["dcc"] = df
        elif 'å¤–å‘¼çº¿ç´¢æ•°' in cols or 'æ¥é€šçº¿ç´¢æ•°' in cols:
            file_map["ams"] = df
    
    return file_map

# ================= 4. ç•Œé¢é€»è¾‘ =================
st.sidebar.header("ğŸ› ï¸ æ•°æ®ä¸Šä¼ ")

# ä¸Šä¼ åŒº
with st.sidebar.form("upload_form"):
    st.write("è¯·ç›´æ¥ä¸Šä¼ åŸå§‹æ–‡ä»¶ï¼ˆæ— éœ€é‡å‘½åï¼‰ï¼š")
    files = st.file_uploader("è¯·ä¸€æ¬¡æ€§ä¸Šä¼ æ‰€æœ‰ 4 ä¸ªæ–‡ä»¶", accept_multiple_files=True)
    if st.form_submit_button("å¼€å§‹åˆ†æ"):
        if files:
            clear_old_files()
            saved_count = 0
            for f in files:
                # ä¿ç•™åŸå§‹æ–‡ä»¶åä¿å­˜ï¼è¿™æ˜¯å…³é”®ï¼
                save_path = os.path.join(DATA_DIR, f.name)
                with open(save_path, "wb") as buffer:
                    buffer.write(f.getbuffer())
                saved_count += 1
            st.success(f"æˆåŠŸä¸Šä¼  {saved_count} ä¸ªæ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–...")
            st.rerun()

# ä¸»é€»è¾‘
data_map = process_all_files()

# æ£€æŸ¥æ˜¯å¦ç¼ºæ–‡ä»¶
missing = [k for k, v in data_map.items() if v is None]

if not missing:
    # === æ‰€æœ‰æ•°æ®å°±ç»ªï¼Œå¼€å§‹å¤„ç† ===
    try:
        df_f = data_map['funnel']
        df_d = data_map['dcc']
        df_a = data_map['ams']
        df_s = data_map['rank']

        # 1. ç»Ÿä¸€åˆ—å
        # æ¼æ–—
        f_rename = {c: 'é—¨åº—åç§°' for c in df_f.columns if 'é—¨åº—' in c}
        f_rename.update({c: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' for c in df_f.columns if 'é¡¾é—®' in c or 'ç®¡å®¶' in c})
        f_rename.update({c: 'çº¿ç´¢é‡' for c in df_f.columns if 'çº¿ç´¢' in c and 'é‡' in c})
        f_rename.update({c: 'åˆ°åº—é‡' for c in df_f.columns if 'åˆ°åº—' in c and 'é‡' in c})
        df_f.rename(columns=f_rename, inplace=True)

        # è´¨æ£€
        d_rename = {c: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' for c in df_d.columns if 'é¡¾é—®' in c}
        df_d.rename(columns=d_rename, inplace=True)

        # æ’å
        s_rename = {c: 'é—¨åº—åç§°' for c in df_s.columns if 'é—¨åº—' in c}
        df_s.rename(columns=s_rename, inplace=True)

        # AMS
        a_rename = {c: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' for c in df_a.columns if 'ç®¡å®¶' in c or 'é¡¾é—®' in c}
        a_rename.update({c: 'conn_num' for c in df_a.columns if 'æ¥é€š' in c})
        a_rename.update({c: 'conn_denom' for c in df_a.columns if 'å¤–å‘¼' in c and 'éœ€' not in c})
        df_a.rename(columns=a_rename, inplace=True)

        # 2. æ•°å€¼è½¬æ¢
        def to_num(s): return pd.to_numeric(s, errors='coerce').fillna(0)
        
        df_f['çº¿ç´¢é‡'] = to_num(df_f['çº¿ç´¢é‡'])
        df_f['åˆ°åº—é‡'] = to_num(df_f['åˆ°åº—é‡'])
        
        # æ‹†åˆ†
        df_stores = df_f[df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('å°è®¡', na=False)].copy()
        df_advisors = df_f[~df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('è®¡|-', na=False)].copy()

        # 3. åˆå¹¶
        # é¡¾é—®å±‚
        full_advisors = pd.merge(df_advisors, df_d, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        if 'conn_num' in df_a.columns:
            full_advisors = pd.merge(full_advisors, df_a, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
            full_advisors['conn_num'] = to_num(full_advisors['conn_num'])
            full_advisors['conn_denom'] = to_num(full_advisors['conn_denom'])

        # é—¨åº—å±‚
        full_stores = pd.merge(df_stores, df_s, on='é—¨åº—åç§°', how='left')
        
        # 4. æ¸²æŸ“çœ‹æ¿
        st.title("ğŸ“Š Audi DCC æ•ˆèƒ½çœ‹æ¿")
        
        mode = st.radio("æŸ¥çœ‹ç»´åº¦", ["é—¨åº—æ’å", "é¡¾é—®æ˜ç»†"], horizontal=True)
        
        if mode == "é—¨åº—æ’å":
            st.subheader("ğŸ† å…¨åŒºé—¨åº—æ€»è§ˆ")
            
            # è¡¥å…¨å¯èƒ½ç¼ºå¤±çš„åˆ—
            for c in ['è´¨æ£€æ€»åˆ†', 'S_60s']:
                if c not in full_stores.columns: full_stores[c] = 0
            else:
                full_stores['è´¨æ£€æ€»åˆ†'] = to_num(full_stores['è´¨æ£€æ€»åˆ†'])

            # æ ¸å¿ƒKPI
            k1, k2, k3 = st.columns(3)
            k1.metric("æ€»çº¿ç´¢", int(full_stores['çº¿ç´¢é‡'].sum()))
            k2.metric("æ€»åˆ°åº—", int(full_stores['åˆ°åº—é‡'].sum()))
            avg_score = full_stores[full_stores['è´¨æ£€æ€»åˆ†']>0]['è´¨æ£€æ€»åˆ†'].mean()
            k3.metric("å¹³å‡è´¨æ£€åˆ†", f"{avg_score:.1f}")

            # è¡¨æ ¼
            disp_cols = ['é—¨åº—åç§°', 'çº¿ç´¢é‡', 'åˆ°åº—é‡', 'è´¨æ£€æ€»åˆ†']
            # åŠ¨æ€åŠ å…¥å­˜åœ¨çš„åˆ—
            if '60ç§’é€šè¯' in full_stores.columns: disp_cols.append('60ç§’é€šè¯')
            
            st.dataframe(
                full_stores[[c for c in disp_cols if c in full_stores.columns]]
                .sort_values('è´¨æ£€æ€»åˆ†', ascending=False)
                .style.background_gradient(subset=['è´¨æ£€æ€»åˆ†'], cmap='RdYlGn'),
                use_container_width=True
            )

        else:
            st.subheader("ğŸ‘¤ é¡¾é—®æ˜ç»†")
            sel_store = st.selectbox("é€‰æ‹©é—¨åº—", full_stores['é—¨åº—åç§°'].unique())
            subset = full_advisors[full_advisors['é—¨åº—åç§°'] == sel_store].copy()
            
            # è®¡ç®—åˆ°åº—ç‡
            subset['çº¿ç´¢åˆ°åº—ç‡'] = (subset['åˆ°åº—é‡'] / subset['çº¿ç´¢é‡'].replace(0, 1)).apply(lambda x: f"{x:.1%}")
            
            st.dataframe(subset[['é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'çº¿ç´¢é‡', 'åˆ°åº—é‡', 'çº¿ç´¢åˆ°åº—ç‡', 'è´¨æ£€æ€»åˆ†']], use_container_width=True)
            
            if 'S_60s' in subset.columns and 'conn_num' in subset.columns:
                subset['æ¥é€šç‡'] = subset['conn_num'] / subset['conn_denom'].replace(0, 1)
                fig = px.scatter(subset, x='æ¥é€šç‡', y='S_60s', size='çº¿ç´¢é‡', color='è´¨æ£€æ€»åˆ†', hover_name='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', title='æ¥é€šç‡ vs 60ç§’è¯æœ¯')
                st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        st.code(traceback.format_exc())

else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼ç›®å‰æ•°æ®ä¸ºç©ºã€‚")
    st.warning(f"è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶ã€‚ç›®å‰è¯†åˆ«åˆ°çš„æ–‡ä»¶ç±»å‹ï¼š")
    
    cols = st.columns(4)
    names = {"funnel": "æ¼æ–—è¡¨", "dcc": "é¡¾é—®è´¨æ£€", "ams": "AMSè¡¨", "rank": "é—¨åº—æ’å"}
    for i, (key, df) in enumerate(data_map.items()):
        status = "âœ… å·²è¯†åˆ«" if df is not None else "âŒ æœªæ‰¾åˆ°"
        cols[i].metric(names[key], status)
    
    if data_map['rank'] is None and os.path.exists(PATH_S):
        st.error("æç¤ºï¼šé—¨åº—æ’åè¡¨è™½ç„¶ä¸Šä¼ äº†ï¼Œä½†æ²¡æ‰¾åˆ°'é—¨åº—åç§°'åˆ—ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
