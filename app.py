import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from datetime import datetime

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")

st.markdown("""
<style>
    .top-container {display: flex; align-items: center; justify-content: space-between; padding-bottom: 20px; border-bottom: 2px solid #f0f0f0;}
    .metric-card {background-color: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    div[data-testid="stSelectbox"] {min-width: 200px;}
    .big-font {font-size: 18px !important; font-weight: bold;}
    /* ä¼˜åŒ–æäº¤æŒ‰é’®æ ·å¼ */
    div[data-testid="stFormSubmitButton"] button {
        width: 100%;
        background-color: #bb0a30;
        color: white;
        border: none;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ================= 2. å®‰å…¨é”ä¸æ–‡ä»¶å­˜å‚¨ =================
ADMIN_PASSWORD = "AudiSARR3" 

DATA_DIR = "data_store"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)
PATH_F = os.path.join(DATA_DIR, "funnel.xlsx")      # 1. æ¼æ–—
PATH_D = os.path.join(DATA_DIR, "dcc.xlsx")         # 2. é¡¾é—®è´¨æ£€
PATH_A = os.path.join(DATA_DIR, "ams.xlsx")         # 3. AMS
PATH_S = os.path.join(DATA_DIR, "store_rank.csv")   # 4. é—¨åº—æ’å

def save_uploaded_file(uploaded_file, save_path):
    # å¼ºåˆ¶è¦†ç›–ä¿å­˜
    with open(save_path, "wb") as f: f.write(uploaded_file.getbuffer())
    return True

# ================= 3. ä¾§è¾¹æ é€»è¾‘ (ä½¿ç”¨ Form è§£å†³ç‚¹å‡»æ— ååº”é—®é¢˜) =================
with st.sidebar:
    st.header("âš™ï¸ ç®¡ç†é¢æ¿")
    has_data = os.path.exists(PATH_F) and os.path.exists(PATH_D) and os.path.exists(PATH_A) and os.path.exists(PATH_S)
    
    if has_data: st.success("âœ… æ•°æ®çŠ¶æ€ï¼šå·²å°±ç»ª")
    else: st.warning("âš ï¸ æš‚æ— æ•°æ®")
    st.markdown("---")
    
    with st.expander("ğŸ” æ›´æ–°æ•°æ® (ä»…é™ç®¡ç†å‘˜)", expanded=True):
        pwd = st.text_input("è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")
        
        if pwd == ADMIN_PASSWORD:
            st.info("ğŸ”“ èº«ä»½éªŒè¯é€šè¿‡ï¼Œè¯·ä¸Šä¼ æ•°æ®ï¼š")
            
            # --- ä½¿ç”¨ st.form ç¡®ä¿æäº¤ç¨³å®š ---
            with st.form("data_update_form", clear_on_submit=False):
                st.markdown("##### å¿…é¡»ä¸Šä¼ æ‰€æœ‰ 4 ä¸ªæ–‡ä»¶ï¼š")
                new_f = st.file_uploader("1. æ¼æ–—æŒ‡æ ‡è¡¨", type=["xlsx", "csv"])
                new_d = st.file_uploader("2. é¡¾é—®è´¨æ£€è¡¨", type=["xlsx", "csv"])
                new_a = st.file_uploader("3. AMSè·Ÿè¿›è¡¨", type=["xlsx", "csv"])
                new_s = st.file_uploader("4. é—¨åº—æ’åè¡¨", type=["xlsx", "csv"]) 
                
                # æäº¤æŒ‰é’®
                submitted = st.form_submit_button("ğŸš€ ç¡®è®¤å¹¶æ›´æ–°æ•°æ®")
                
                if submitted:
                    if new_f and new_d and new_a and new_s:
                        with st.spinner("æ­£åœ¨ä¿å­˜æ–‡ä»¶å¹¶å¤„ç†..."):
                            save_uploaded_file(new_f, PATH_F)
                            save_uploaded_file(new_d, PATH_D)
                            save_uploaded_file(new_a, PATH_A)
                            save_uploaded_file(new_s, PATH_S)
                        
                        st.success("âœ… æ•°æ®æ›´æ–°æˆåŠŸï¼é¡µé¢å³å°†åˆ·æ–°...")
                        st.rerun()
                    else:
                        st.error("âŒ æ›´æ–°å¤±è´¥ï¼šè¯·ç¡®ä¿ 4 ä¸ªæ–‡ä»¶å…¨éƒ¨éƒ½å·²ä¸Šä¼ ã€‚")
        elif pwd:
            st.error("å¯†ç é”™è¯¯")

# ================= 4. æ•°æ®å¤„ç†é€»è¾‘ (å¢å¼ºå®¹é”™) =================
def smart_read(file_path, is_rank_file=False):
    """æ™ºèƒ½è¯»å–ï¼Œæ”¯æŒcsv/xlsxï¼Œé’ˆå¯¹æ’åè¡¨æ”¯æŒè·³è¿‡é¦–è¡Œ"""
    try:
        if isinstance(file_path, str):
            is_csv = file_path.endswith('.csv') or file_path.endswith('.txt')
        else:
            is_csv = file_path.name.endswith('.csv') or file_path.name.endswith('.txt')
            
        if is_csv:
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path)
            
        # é’ˆå¯¹é—¨åº—æ’åè¡¨çš„ç‰¹æ®Šå¤„ç† (æ£€æµ‹æ˜¯å¦åŒ…å« metadata å¤´)
        if is_rank_file:
            # å®šä¹‰æˆ‘ä»¬åœ¨æ‰¾çš„å…³é”®åˆ—
            target_cols = ['é—¨åº—åç§°', 'è´¨æ£€æ€»åˆ†', 'æ’å']
            # å¦‚æœç¬¬ä¸€è¡Œè¡¨å¤´é‡Œæ²¡æ‰¾åˆ°è¿™äº›åˆ—ï¼Œå°è¯•è¯»ç¬¬äºŒè¡Œä½œä¸ºè¡¨å¤´
            if not any(col in df.columns for col in target_cols):
                if is_csv: df = pd.read_csv(file_path, header=1)
                else: df = pd.read_excel(file_path, header=1)
        return df
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        return None

def clean_percent_col(df, col_name):
    if col_name not in df.columns: return
    series = df[col_name].astype(str).str.strip().str.replace('%', '', regex=False)
    numeric_series = pd.to_numeric(series, errors='coerce').fillna(0)
    if numeric_series.max() > 1.0:
        df[col_name] = numeric_series / 100
    else:
        df[col_name] = numeric_series

def safe_div(df, num_col, denom_col):
    num = pd.to_numeric(df[num_col], errors='coerce').fillna(0)
    denom = pd.to_numeric(df[denom_col], errors='coerce').fillna(0)
    return (num / denom).replace([np.inf, -np.inf], 0).fillna(0)

def process_data(path_f, path_d, path_a, path_s):
    try:
        raw_f = smart_read(path_f)
        raw_d = smart_read(path_d)
        raw_a = smart_read(path_a)
        raw_s = smart_read(path_s, is_rank_file=True)
        
        # åªè¦æœ‰ä¸€ä¸ªæ–‡ä»¶æ²¡è¯»å‡ºæ¥ï¼Œå°±è¿”å› None
        if raw_f is None or raw_d is None or raw_a is None or raw_s is None: 
            return None, None

        # ================= A. Funnel (æ¼æ–—) =================
        # æ¨¡ç³ŠåŒ¹é…åˆ—åï¼Œå¢åŠ é²æ£’æ€§
        store_col = next((c for c in raw_f.columns if 'ä»£ç†å•†' in str(c) or 'é—¨åº—' in str(c)), raw_f.columns[0])
        name_col = next((c for c in raw_f.columns if 'ç®¡å®¶' in str(c) or 'é¡¾é—®' in str(c)), raw_f.columns[1])
        col_leads = 'çº¿ä¸Š_æœ‰æ•ˆçº¿ç´¢æ•°' if 'çº¿ä¸Š_æœ‰æ•ˆçº¿ç´¢æ•°' in raw_f.columns else 'çº¿ç´¢é‡'
        col_visits = 'çº¿ä¸Š_åˆ°åº—æ•°' if 'çº¿ä¸Š_åˆ°åº—æ•°' in raw_f.columns else 'åˆ°åº—é‡'
        col_excel_rate = next((c for c in raw_f.columns if 'ç‡' in str(c) and ('åˆ°åº—' in str(c) or 'æœ‰æ•ˆ' in str(c))), None)

        rename_dict = {store_col: 'é—¨åº—åç§°', name_col: 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', col_leads: 'çº¿ç´¢é‡', col_visits: 'åˆ°åº—é‡'}
        if col_excel_rate: rename_dict[col_excel_rate] = 'Excel_Rate'
        
        df_f = raw_f.rename(columns=rename_dict)
        # åŒºåˆ†é—¨åº—è¡Œå’Œé¡¾é—®è¡Œ
        df_store_data = df_f[df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('å°è®¡', na=False)].copy()
        df_advisor_data = df_f[~df_f['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.contains('è®¡|-', na=False)].copy()

        for df in [df_store_data, df_advisor_data]:
            df['çº¿ç´¢é‡'] = pd.to_numeric(df['çº¿ç´¢é‡'], errors='coerce').fillna(0)
            df['åˆ°åº—é‡'] = pd.to_numeric(df['åˆ°åº—é‡'], errors='coerce').fillna(0)
            if 'Excel_Rate' in df.columns:
                clean_percent_col(df, 'Excel_Rate')
                df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = df['Excel_Rate']
            else:
                df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] = safe_div(df, 'åˆ°åº—é‡', 'çº¿ç´¢é‡')
            df['çº¿ç´¢åˆ°åº—ç‡'] = (df['çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼'] * 100).map('{:.1f}%'.format)

        # ================= B. DCC (é¡¾é—®è´¨æ£€) =================
        wechat_col = 'æ·»åŠ å¾®ä¿¡.1' if 'æ·»åŠ å¾®ä¿¡.1' in raw_d.columns else 'æ·»åŠ å¾®ä¿¡'
        df_d = raw_d.rename(columns={
            'é¡¾é—®åç§°': 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'è´¨æ£€æ€»åˆ†': 'è´¨æ£€æ€»åˆ†',
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        })
        # å…¼å®¹å¤„ç†
        if wechat_col in raw_d.columns:
            df_d['S_Wechat'] = raw_d[wechat_col]
        else:
            df_d['S_Wechat'] = 0
        
        score_cols = ['è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat', 'S_Time']
        for c in score_cols:
            if c in df_d.columns:
                df_d[c] = pd.to_numeric(df_d[c], errors='coerce') 
        
        # åªå–å­˜åœ¨çš„åˆ—
        existing_cols = [c for c in (['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] + score_cols) if c in df_d.columns]
        df_d = df_d[existing_cols]

        # ================= C. Store Scores (é—¨åº—è´¨æ£€ - ç›´æ¥è¯»å–æ–‡ä»¶4) =================
        df_s = raw_s.rename(columns={
            '60ç§’é€šè¯': 'S_60s', 'ç”¨è½¦éœ€æ±‚': 'S_Needs', 'è½¦å‹ä¿¡æ¯': 'S_Car', 
            'æ”¿ç­–ç›¸å…³': 'S_Policy', 'æ˜ç¡®åˆ°åº—æ—¶é—´': 'S_Time'
        })
        s_wechat_col = 'æ·»åŠ å¾®ä¿¡.1' if 'æ·»åŠ å¾®ä¿¡.1' in raw_s.columns else 'æ·»åŠ å¾®ä¿¡'
        if s_wechat_col in raw_s.columns:
            df_s['S_Wechat'] = raw_s[s_wechat_col]
        else:
            df_s['S_Wechat'] = 0
        
        store_score_cols = ['é—¨åº—åç§°', 'è´¨æ£€æ€»åˆ†', 'S_60s', 'S_Needs', 'S_Car', 'S_Policy', 'S_Wechat', 'S_Time']
        available_store_cols = [c for c in store_score_cols if c in df_s.columns]
        df_s = df_s[available_store_cols]
        for c in available_store_cols:
            if c != 'é—¨åº—åç§°':
                df_s[c] = pd.to_numeric(df_s[c], errors='coerce')

        # ================= D. AMS (è·Ÿè¿›æ•°æ®) =================
        # æ¨¡ç³ŠåŒ¹é… AMS åˆ—å
        cols_config = [
            ({'ç®¡å®¶å§“å'}, 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶'),
            ({'DCCå¹³å‡é€šè¯æ—¶é•¿'}, 'é€šè¯æ—¶é•¿'),
            ({'DCCæ¥é€šçº¿ç´¢æ•°'}, 'conn_num'), ({'DCCå¤–å‘¼çº¿ç´¢æ•°'}, 'conn_denom'),
            ({'DCCåŠæ—¶å¤„ç†çº¿ç´¢'}, 'timely_num'), ({'éœ€å¤–å‘¼çº¿ç´¢æ•°'}, 'timely_denom'),
            ({'äºŒæ¬¡å¤–å‘¼çº¿ç´¢æ•°'}, 'call2_num'), ({'éœ€å†å‘¼çº¿ç´¢æ•°'}, 'call2_denom'),
            ({'DCCä¸‰æ¬¡å¤–å‘¼çš„çº¿ç´¢æ•°', 'ä¸‰æ¬¡å¤–å‘¼çº¿ç´¢æ•°'}, 'call3_num'), 
            ({'DCCäºŒå‘¼çŠ¶æ€ä¸ºéœ€å†å‘¼çš„çº¿ç´¢æ•°', 'äºŒå‘¼çŠ¶æ€ä¸ºéœ€å†å‘¼'}, 'call3_denom')
        ]
        found_rename_map = {}
        for keywords, target_name in cols_config:
            found_col = None
            for col in raw_a.columns:
                for k in keywords:
                    if k in str(col).strip(): found_col = col; break
                if found_col: break
            if found_col: found_rename_map[found_col] = target_name
        
        df_a = raw_a.rename(columns=found_rename_map)
        
        all_ams_calc_cols = ['conn_num', 'conn_denom', 'timely_num', 'timely_denom', 
                             'call2_num', 'call2_denom', 'call3_num', 'call3_denom']
        for c in all_ams_calc_cols:
            if c not in df_a.columns: df_a[c] = 0
            else: df_a[c] = pd.to_numeric(df_a[c], errors='coerce').fillna(0)

        df_a['å¤–å‘¼æ¥é€šç‡'] = safe_div(df_a, 'conn_num', 'conn_denom')
        df_a['DCCåŠæ—¶å¤„ç†ç‡'] = safe_div(df_a, 'timely_num', 'timely_denom')
        df_a['DCCäºŒæ¬¡å¤–å‘¼ç‡'] = safe_div(df_a, 'call2_num', 'call2_denom')
        df_a['DCCä¸‰æ¬¡å¤–å‘¼ç‡'] = safe_div(df_a, 'call3_num', 'call3_denom')

        final_ams_cols = ['é‚€çº¦ä¸“å‘˜/ç®¡å®¶', 'é€šè¯æ—¶é•¿', 'å¤–å‘¼æ¥é€šç‡', 'DCCåŠæ—¶å¤„ç†ç‡', 'DCCäºŒæ¬¡å¤–å‘¼ç‡', 'DCCä¸‰æ¬¡å¤–å‘¼ç‡'] + all_ams_calc_cols
        # ä»…ä¿ç•™å­˜åœ¨çš„åˆ—
        final_ams_cols = [c for c in final_ams_cols if c in df_a.columns]
        df_a = df_a[final_ams_cols]

        # ================= E. Merge =================
        # æ¸…ç†ç©ºæ ¼
        for df in [df_store_data, df_advisor_data, df_d, df_a, df_s]:
            if 'é‚€çº¦ä¸“å‘˜/ç®¡å®¶' in df.columns: df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'] = df['é‚€çº¦ä¸“å‘˜/ç®¡å®¶'].astype(str).str.strip()
            if 'é—¨åº—åç§°' in df.columns: df['é—¨åº—åç§°'] = df['é—¨åº—åç§°'].astype(str).str.strip()

        # 1. é¡¾é—®å…¨é‡è¡¨
        full_advisors = pd.merge(df_advisor_data, df_d, on='é‚€çº¦ä¸“å‘˜/ç®¡å®¶', how='left')
        full_advisors = pd.merge(full_
