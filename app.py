import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import os

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")

st.markdown(
    """
<style>
    .metric-card {background-color: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    div[data-testid="stSelectbox"] {min-width: 200px;}
    div[data-testid="stFormSubmitButton"] button {
        width: 100%;
        background-color: #bb0a30;
        color: white;
        border: none;
        font-weight: bold;
    }
    div[data-testid="stFormSubmitButton"] button:hover {
        background-color: #990000;
        color: white;
    }
</style>
""",
    unsafe_allow_html=True,
)

# ================= 2. åŸºç¡€é…ç½® =================
ADMIN_PASSWORD = "AudiSARR3"
DATA_DIR = "data_store"
os.makedirs(DATA_DIR, exist_ok=True)

# âœ… å›ºå®š store_rank ä»¥ xlsx ä¸ºä¸»ï¼›å…¼å®¹è¯¯ä¼  csv
PATH_F = os.path.join(DATA_DIR, "funnel.xlsx")
PATH_D = os.path.join(DATA_DIR, "dcc.xlsx")
PATH_A = os.path.join(DATA_DIR, "ams.xlsx")
PATH_S_XLSX = os.path.join(DATA_DIR, "store_rank.xlsx")
PATH_S_CSV = os.path.join(DATA_DIR, "store_rank.csv")


def save_uploaded_file(uploaded_file, save_path: str) -> bool:
    try:
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        return True
    except Exception as e:
        st.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
        return False


def get_store_rank_path():
    if os.path.exists(PATH_S_XLSX):
        return PATH_S_XLSX
    if os.path.exists(PATH_S_CSV):
        return PATH_S_CSV
    return None


# ================= 3. ä¾§è¾¹æ  =================
with st.sidebar:
    st.image(
        "https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Audi-Logo_2016.svg/1200px-Audi-Logo_2016.svg.png",
        width=150,
    )
    st.header("âš™ï¸ ç®¡ç†é¢æ¿")

    store_rank_path = get_store_rank_path()
    has_data = (
        os.path.exists(PATH_F)
        and os.path.exists(PATH_D)
        and os.path.exists(PATH_A)
        and (store_rank_path is not None)
    )

    if has_data:
        st.success("âœ… æ•°æ®çŠ¶æ€ï¼šå·²å°±ç»ª")
    else:
        st.warning("âš ï¸ æš‚æ— æ•°æ®")
    st.markdown("---")

    with st.expander("ğŸ” æ›´æ–°æ•°æ® (ä»…é™ç®¡ç†å‘˜)", expanded=True):
        pwd = st.text_input("è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")

        if pwd == ADMIN_PASSWORD:
            st.info("ğŸ”“ èº«ä»½éªŒè¯é€šè¿‡")
            with st.form("data_update_form", clear_on_submit=False):
                st.markdown("##### è¯·ä¸Šä¼ æ‰€æœ‰ 4 ä¸ªæ–‡ä»¶ï¼š")
                new_f = st.file_uploader("1. æ¼æ–—è¡¨ (funnel)", type=["xlsx", "csv"])
                new_d = st.file_uploader("2. é¡¾é—®è´¨æ£€è¡¨ (dcc)", type=["xlsx", "csv"])
                new_a = st.file_uploader("3. AMSè¡¨ (ams)", type=["xlsx", "csv"])
                new_s = st.file_uploader("4. é—¨åº—æ’åè¡¨ (store_rank)", type=["xlsx", "csv"])

                if st.form_submit_button("ğŸš€ ç¡®è®¤å¹¶æ›´æ–°æ•°æ®"):
                    if new_f and new_d and new_a and new_s:
                        with st.spinner("æ­£åœ¨ä¿å­˜å¹¶å¤„ç†..."):
                            s1 = save_uploaded_file(new_f, PATH_F)
                            s2 = save_uploaded_file(new_d, PATH_D)
                            s3 = save_uploaded_file(new_a, PATH_A)

                            # âœ… store_rank æ ¹æ®ä¸Šä¼ çœŸå®åç¼€ä¿å­˜
                            if new_s.name.lower().endswith(".xlsx"):
                                if os.path.exists(PATH_S_CSV):
                                    try:
                                        os.remove(PATH_S_CSV)
                                    except Exception:
                                        pass
                                s4 = save_uploaded_file(new_s, PATH_S_XLSX)
                            else:
                                if os.path.exists(PATH_S_XLSX):
                                    try:
                                        os.remove(PATH_S_XLSX)
                                    except Exception:
                                        pass
                                s4 = save_uploaded_file(new_s, PATH_S_CSV)

                            if s1 and s2 and s3 and s4:
                                st.success("âœ… æ›´æ–°æˆåŠŸï¼æ­£åœ¨åˆ·æ–°é¡µé¢...")
                                st.rerun()
                    else:
                        st.error("âŒ è¯·ç¡®ä¿ 4 ä¸ªæ–‡ä»¶å…¨éƒ¨ä¸Šä¼ å®Œæ¯•ã€‚")
        elif pwd:
            st.error("å¯†ç é”™è¯¯")


# ================= 4. æ•°æ®è¯»å–ä¸å¤„ç† =================
def dedupe_columns(columns):
    """æŠŠé‡å¤åˆ—åå˜æˆ: åˆ—å, åˆ—å__1, åˆ—å__2 ..."""
    seen = {}
    new_cols = []
    for c in list(columns):
        c = str(c)
        if c not in seen:
            seen[c] = 0
            new_cols.append(c)
        else:
            seen[c] += 1
            new_cols.append(f"{c}__{seen[c]}")
    return new_cols


def smart_read(file_path: str):
    """å¢å¼ºç‰ˆè¯»å–ï¼š
    - xlsx: read_excel(header=None)
    - csv: å¤šç¼–ç å°è¯•
    - å…œåº•ï¼šè‹¥æ–‡ä»¶ç­¾åæ˜¯ PK..ï¼ˆå…¶å®æ˜¯xlsxï¼‰ï¼Œå³ä¾¿åç¼€æ˜¯csvä¹ŸæŒ‰xlsxè¯»
    - å…³é”®ï¼šåˆ—åå»é‡ï¼Œé¿å… df['æ·»åŠ å¾®ä¿¡'] å–å‡ºå¤šåˆ—
    """
    try:
        if not file_path or not os.path.exists(file_path):
            return None

        df = None

        # å…œåº•ï¼šç­¾ååˆ¤æ–­ï¼ˆxlsx/docx/pptx éƒ½æ˜¯ zip: PK..ï¼‰
        try:
            with open(file_path, "rb") as f:
                sig = f.read(4)
            if sig == b"PK\x03\x04":
                df = pd.read_excel(file_path, header=None)
        except Exception:
            pass

        if df is None:
            if file_path.lower().endswith(".xlsx"):
                df = pd.read_excel(file_path, header=None)
            else:
                encodings = ["utf-8-sig", "gb18030", "utf-16"]
                for enc in encodings:
                    try:
                        df = pd.read_csv(
                            file_path,
                            header=None,
                            encoding=enc,
                            engine="python",
                            on_bad_lines="skip",
                        )
                        break
                    except (UnicodeDecodeError, pd.errors.ParserError):
                        continue
                    except Exception:
                        continue

        if df is None:
            st.error(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {os.path.basename(file_path)}")
            return None

        # æ™ºèƒ½æ‰¾è¡¨å¤´
        header_row = 0
        keywords = ["é—¨åº—", "é¡¾é—®", "ç®¡å®¶", "æ’å", "ä»£ç†å•†", "åºå·", "çº¿ç´¢", "è´¨æ£€"]
        for i in range(min(8, len(df))):
            row_values = df.iloc[i].astype(str).str.cat(sep=",")
            if any(k in row_values for k in keywords):
                header_row = i
                break

        df.columns = df.iloc[header_row]
        df = df[header_row + 1 :].reset_index(drop=True)

        # æ¸…ç†åˆ—å
        df.columns = (
            df.columns.astype(str)
            .str.strip()
            .str.replace("\n", "", regex=False)
            .str.replace("\r", "", regex=False)
        )

        # âœ… å»é‡åˆ—å
        df.columns = dedupe_columns(df.columns)

        # åˆ é™¤ç©ºåˆ—
        df = df.loc[:, df.columns.notna()]
        df = df.loc[:, df.columns != "nan"]

        return df

    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶ç³»ç»Ÿçº§å¤±è´¥: {os.path.basename(file_path)} - {e}")
        return None


def safe_div(df, num_col, denom_col):
    if num_col not in df.columns or denom_col not in df.columns:
        return 0
    num = pd.to_numeric(df[num_col], errors="coerce").fillna(0)
    denom = pd.to_numeric(df[denom_col], errors="coerce").fillna(0)
    return (num / denom).replace([np.inf, -np.inf], 0).fillna(0)


@st.cache_data(ttl=300)
def process_data(path_f, path_d, path_a, store_rank_path):
    try:
        raw_f = smart_read(path_f)
        raw_d = smart_read(path_d)
        raw_a = smart_read(path_a)
        raw_s = smart_read(store_rank_path)

        if raw_f is None or raw_d is None or raw_a is None or raw_s is None:
            return None, None

        # --- A. æ¼æ–—è¡¨ ---
        f_cols = raw_f.columns
        col_store = next((c for c in f_cols if "é—¨åº—" in str(c) or "ä»£ç†" in str(c)), "é—¨åº—åç§°")
        col_name = next((c for c in f_cols if "é¡¾é—®" in str(c) or "ç®¡å®¶" in str(c)), "é‚€çº¦ä¸“å‘˜/ç®¡å®¶")
        col_leads = next((c for c in f_cols if "æœ‰æ•ˆçº¿ç´¢" in str(c) or "çº¿ç´¢é‡" in str(c)), "çº¿ç´¢é‡")
        col_visits = next((c for c in f_cols if "åˆ°åº—" in str(c) and "ç‡" not in str(c)), "åˆ°åº—é‡")

        df_f = raw_f.rename(
            columns={
                col_store: "é—¨åº—åç§°",
                col_name: "é‚€çº¦ä¸“å‘˜/ç®¡å®¶",
                col_leads: "çº¿ç´¢é‡",
                col_visits: "åˆ°åº—é‡",
            }
        )

        mask_sub = df_f["é‚€çº¦ä¸“å‘˜/ç®¡å®¶"].astype(str).str.contains("å°è®¡", na=False)
        df_store_data = df_f[mask_sub].copy()
        df_advisor_data = df_f[~mask_sub].copy()

        for df in [df_store_data, df_advisor_data]:
            df["çº¿ç´¢é‡"] = pd.to_numeric(df["çº¿ç´¢é‡"], errors="coerce").fillna(0)
            df["åˆ°åº—é‡"] = pd.to_numeric(df["åˆ°åº—é‡"], errors="coerce").fillna(0)
            df["çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼"] = safe_div(df, "åˆ°åº—é‡", "çº¿ç´¢é‡")
            df["çº¿ç´¢åˆ°åº—ç‡"] = (df["çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼"] * 100).map("{:.1f}%".format)

        # --- B. é¡¾é—®è´¨æ£€è¡¨ ---
        d_map = {
            "é¡¾é—®åç§°": "é‚€çº¦ä¸“å‘˜/ç®¡å®¶",
            "è´¨æ£€æ€»åˆ†": "è´¨æ£€æ€»åˆ†",
            "60ç§’é€šè¯": "S_60s",
            "ç”¨è½¦éœ€æ±‚": "S_Needs",
            "è½¦å‹ä¿¡æ¯": "S_Car",
            "æ”¿ç­–ç›¸å…³": "S_Policy",
            "æ˜ç¡®åˆ°åº—æ—¶é—´": "S_Time",
        }
        df_d = raw_d.rename(columns=d_map)

        # âœ… å¤šåˆ—å®‰å…¨ï¼šåŒ¹é…æ‰€æœ‰â€œæ·»åŠ å¾®ä¿¡â€ç›¸å…³åˆ—ï¼Œå–ç¬¬ä¸€åˆ—
        wechat_cols = [c for c in df_d.columns if ("å¾®ä¿¡" in str(c) and "æ·»åŠ " in str(c))]
        if wechat_cols:
            df_d["S_Wechat"] = pd.to_numeric(df_d[wechat_cols].iloc[:, 0], errors="coerce").fillna(0)
        else:
            df_d["S_Wechat"] = 0

        # å…œåº•ï¼šè‹¥é¡¾é—®åˆ—åä¸åŒ
        if "é‚€çº¦ä¸“å‘˜/ç®¡å®¶" not in df_d.columns:
            if "ç®¡å®¶" in df_d.columns:
                df_d.rename(columns={"ç®¡å®¶": "é‚€çº¦ä¸“å‘˜/ç®¡å®¶"}, inplace=True)
            elif "é¡¾é—®" in df_d.columns:
                df_d.rename(columns={"é¡¾é—®": "é‚€çº¦ä¸“å‘˜/ç®¡å®¶"}, inplace=True)

        num_cols = ["è´¨æ£€æ€»åˆ†", "S_60s", "S_Time", "S_Needs", "S_Car", "S_Policy", "S_Wechat"]
        for c in num_cols:
            if c in df_d.columns:
                df_d[c] = pd.to_numeric(df_d[c], errors="coerce")

        # --- C. é—¨åº—æ’åè¡¨ ---
        s_map = {
            "60ç§’é€šè¯": "S_60s",
            "ç”¨è½¦éœ€æ±‚": "S_Needs",
            "è½¦å‹ä¿¡æ¯": "S_Car",
            "æ”¿ç­–ç›¸å…³": "S_Policy",
            "æ˜ç¡®åˆ°åº—æ—¶é—´": "S_Time",
        }
        s_store_raw = next((c for c in raw_s.columns if "é—¨åº—" in str(c) and "ID" not in str(c)), "é—¨åº—åç§°")
        df_s = raw_s.rename(columns={**s_map, s_store_raw: "é—¨åº—åç§°"})

        # âœ… å¤šåˆ—å®‰å…¨ï¼šé—¨åº—æ’åè¡¨çš„â€œæ·»åŠ å¾®ä¿¡â€åˆ—
        s_wechat_cols = [c for c in df_s.columns if ("å¾®ä¿¡" in str(c) and "æ·»åŠ " in str(c))]
        if s_wechat_cols:
            df_s["S_Wechat"] = pd.to_numeric(df_s[s_wechat_cols].iloc[:, 0], errors="coerce").fillna(0)
        else:
            df_s["S_Wechat"] = 0

        for c in ["è´¨æ£€æ€»åˆ†", "S_60s", "S_Time", "S_Needs", "S_Car", "S_Policy", "S_Wechat"]:
            if c in df_s.columns:
                df_s[c] = pd.to_numeric(df_s[c], errors="coerce")

        # --- D. AMSè¡¨ ---
        a_map = {}
        for c in raw_a.columns:
            sc = str(c)
            if "æ¥é€š" in sc and "çº¿ç´¢" in sc and "ç‡" not in sc:
                a_map[c] = "conn_num"
            if "å¤–å‘¼" in sc and "çº¿ç´¢" in sc and "éœ€" not in sc and "ç‡" not in sc:
                a_map[c] = "conn_denom"
            if "ç®¡å®¶" in sc or "é¡¾é—®" in sc:
                a_map[c] = "é‚€çº¦ä¸“å‘˜/ç®¡å®¶"
            if "å¹³å‡é€šè¯æ—¶é•¿" in sc:
                a_map[c] = "é€šè¯æ—¶é•¿"

        df_a = raw_a.rename(columns=a_map)
        for c in ["conn_num", "conn_denom", "é€šè¯æ—¶é•¿"]:
            if c not in df_a.columns:
                df_a[c] = 0
            else:
                df_a[c] = pd.to_numeric(df_a[c], errors="coerce").fillna(0)

        # --- E. åˆå¹¶ ---
        for df in [df_advisor_data, df_d, df_a, df_store_data, df_s]:
            if "é‚€çº¦ä¸“å‘˜/ç®¡å®¶" in df.columns:
                df["é‚€çº¦ä¸“å‘˜/ç®¡å®¶"] = df["é‚€çº¦ä¸“å‘˜/ç®¡å®¶"].astype(str).str.strip()
            if "é—¨åº—åç§°" in df.columns:
                df["é—¨åº—åç§°"] = df["é—¨åº—åç§°"].astype(str).str.strip()

        full_advisors = pd.merge(df_advisor_data, df_d, on="é‚€çº¦ä¸“å‘˜/ç®¡å®¶", how="left")

        if "é‚€çº¦ä¸“å‘˜/ç®¡å®¶" in df_a.columns:
            df_a_unique = df_a.groupby("é‚€çº¦ä¸“å‘˜/ç®¡å®¶").first().reset_index()
            full_advisors = pd.merge(full_advisors, df_a_unique, on="é‚€çº¦ä¸“å‘˜/ç®¡å®¶", how="left")

        if "conn_num" in full_advisors.columns and "é—¨åº—åç§°" in full_advisors.columns:
            ams_grp = full_advisors.groupby("é—¨åº—åç§°")[["conn_num", "conn_denom"]].sum().reset_index()
        else:
            ams_grp = pd.DataFrame(columns=["é—¨åº—åç§°", "conn_num", "conn_denom"])

        full_stores = pd.merge(df_store_data, df_s, on="é—¨åº—åç§°", how="left")
        full_stores = pd.merge(full_stores, ams_grp, on="é—¨åº—åç§°", how="left")

        return full_advisors, full_stores

    except Exception as e:
        import traceback

        st.error(f"æ•°æ®å¤„ç†é€»è¾‘é”™è¯¯: {e}")
        st.text(traceback.format_exc())
        return None, None


# ================= 5. ç•Œé¢æ¸²æŸ“ =================
store_rank_path = get_store_rank_path()
has_data = (
    os.path.exists(PATH_F)
    and os.path.exists(PATH_D)
    and os.path.exists(PATH_A)
    and (store_rank_path is not None)
)

if has_data:
    df_advisors, df_stores = process_data(PATH_F, PATH_D, PATH_A, store_rank_path)

    if df_advisors is not None:
        st.sidebar.markdown("---")
        if df_stores is not None and not df_stores.empty and "é—¨åº—åç§°" in df_stores.columns:
            store_options = ["å…¨éƒ¨"] + sorted(list(df_stores["é—¨åº—åç§°"].unique()))
        else:
            store_options = ["å…¨éƒ¨"]

        selected_store = st.sidebar.selectbox("ğŸ­ åˆ‡æ¢é—¨åº—è§†å›¾", store_options)

        if selected_store == "å…¨éƒ¨":
            current_df = df_stores.copy() if df_stores is not None else pd.DataFrame()
            current_df["Name"] = current_df.get("é—¨åº—åç§°", "")
            rank_title = "ğŸ† å…¨åŒºé—¨åº—æ’å"
        else:
            current_df = df_advisors[df_advisors.get("é—¨åº—åç§°", "") == selected_store].copy()
            current_df["Name"] = current_df.get("é‚€çº¦ä¸“å‘˜/ç®¡å®¶", "")
            rank_title = f"ğŸ‘¤ {selected_store} - é¡¾é—®æ’å"

        kpi_leads = current_df["çº¿ç´¢é‡"].sum() if "çº¿ç´¢é‡" in current_df.columns else 0
        kpi_visits = current_df["åˆ°åº—é‡"].sum() if "åˆ°åº—é‡" in current_df.columns else 0
        kpi_rate = (kpi_visits / kpi_leads) if kpi_leads > 0 else 0
        kpi_score = current_df["è´¨æ£€æ€»åˆ†"].mean() if "è´¨æ£€æ€»åˆ†" in current_df.columns else 0

        st.subheader("1ï¸âƒ£ ç»“æœæ¦‚è§ˆ (Result)")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("æ€»æœ‰æ•ˆçº¿ç´¢", f"{int(kpi_leads):,}")
        k2.metric("æ€»å®é™…åˆ°åº—", f"{int(kpi_visits):,}")
        k3.metric("çº¿ç´¢åˆ°åº—ç‡", f"{kpi_rate:.1%}")
        k4.metric("å¹³å‡è´¨æ£€æ€»åˆ†", f"{kpi_score:.1f}")

        st.markdown("---")

        c1, c2 = st.columns(2)
        with c1:
            st.subheader("é€šè¯è´¨é‡åˆ†æ")
            if "S_60s" in current_df.columns and "conn_num" in current_df.columns:
                current_df["æ¥é€šç‡"] = safe_div(current_df, "conn_num", "conn_denom")
                plot_df = current_df.fillna(0)
                fig = px.scatter(
                    plot_df,
                    x="æ¥é€šç‡",
                    y="S_60s",
                    size="çº¿ç´¢é‡" if "çº¿ç´¢é‡" in plot_df.columns else None,
                    color="è´¨æ£€æ€»åˆ†" if "è´¨æ£€æ€»åˆ†" in plot_df.columns else None,
                    hover_name="Name",
                    labels={"S_60s": "60ç§’é€šè¯å æ¯”", "æ¥é€šç‡": "å¤–å‘¼æ¥é€šç‡"},
                )
                fig.update_layout(xaxis_tickformat=".0%", height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("â„¹ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ˜¾ç¤ºé€šè¯è´¨é‡æ•£ç‚¹å›¾ (éœ€ AMS å’Œ è´¨æ£€æ•°æ®)")

        with c2:
            st.subheader(rank_title)
            show_cols = ["Name", "çº¿ç´¢åˆ°åº—ç‡", "è´¨æ£€æ€»åˆ†", "çº¿ç´¢é‡", "åˆ°åº—é‡"]
            if "S_60s" in current_df.columns:
                show_cols.append("S_60s")

            show_cols = [c for c in show_cols if c in current_df.columns]

            if not current_df.empty and show_cols:
                if "çº¿ç´¢é‡" in current_df.columns:
                    view_df = current_df[show_cols].sort_values("çº¿ç´¢é‡", ascending=False)
                else:
                    view_df = current_df[show_cols]
                st.dataframe(view_df, use_container_width=True, height=400, hide_index=True)
            else:
                st.warning("æš‚æ— æ•°æ®")
else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼è¯·åœ¨å·¦ä¾§ç‚¹å‡»â€œæ›´æ–°æ•°æ®â€å¹¶ä¸Šä¼ æ–‡ä»¶ã€‚")
