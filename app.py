import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from datetime import datetime

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="Audi DCC æ•ˆèƒ½çœ‹æ¿", layout="wide", page_icon="ğŸï¸")

st.markdown("""
<style>
    .metric-card {background-color: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);}
    div[data-testid="stSelectbox"] {min-width: 200px;}
    div[data-testid="stFormSubmitButton"] button {
        width: 100%;
        background-color: #bb0a30;
        color: white;
        border: none;
        font-weight: bold;
    }
    div[data-testid="stFormSubmitButton"] button:hover {
        background-color: #990000;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# ================= 2. åŸºç¡€é…ç½® =================
ADMIN_PASSWORD = "AudiSARR3"
DATA_DIR = "data_store"
os.makedirs(DATA_DIR, exist_ok=True)

# âœ… ç»Ÿä¸€ï¼šç¬¬4ä¸ªé—¨åº—æ’åè¡¨å›ºå®šä¸º xlsxï¼ˆæ ¹æ²»ä½ ç°åœ¨çš„æŠ¥é”™ï¼‰
PATH_F = os.path.join(DATA_DIR, "funnel.xlsx")
PATH_D = os.path.join(DATA_DIR, "dcc.xlsx")
PATH_A = os.path.join(DATA_DIR, "ams.xlsx")
PATH_S_XLSX = os.path.join(DATA_DIR, "store_rank.xlsx")
PATH_S_CSV  = os.path.join(DATA_DIR, "store_rank.csv")  # å…¼å®¹è¯¯ä¼ csvï¼ˆå¯é€‰ï¼‰

def save_uploaded_file(uploaded_file, save_path):
    """æŒ‰æŒ‡å®šè·¯å¾„ä¿å­˜ä¸Šä¼ æ–‡ä»¶ï¼ˆå­—èŠ‚åŸæ ·å†™å…¥ï¼‰"""
    try:
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        return True
    except Exception as e:
        st.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
        return False

def get_store_rank_path():
    """ä¼˜å…ˆä½¿ç”¨xlsxï¼›å¦‚æœåªæœ‰csvåˆ™ç”¨csv"""
    if os.path.exists(PATH_S_XLSX):
        return PATH_S_XLSX
    if os.path.exists(PATH_S_CSV):
        return PATH_S_CSV
    return None

# ================= 3. ä¾§è¾¹æ  =================
with st.sidebar:
    st.image(
        "https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Audi-Logo_2016.svg/1200px-Audi-Logo_2016.svg.png",
        width=150
    )
    st.header("âš™ï¸ ç®¡ç†é¢æ¿")

    store_rank_path = get_store_rank_path()
    has_data = (
        os.path.exists(PATH_F)
        and os.path.exists(PATH_D)
        and os.path.exists(PATH_A)
        and (store_rank_path is not None)
    )

    if has_data:
        st.success("âœ… æ•°æ®çŠ¶æ€ï¼šå·²å°±ç»ª")
    else:
        st.warning("âš ï¸ æš‚æ— æ•°æ®")
    st.markdown("---")

    with st.expander("ğŸ” æ›´æ–°æ•°æ® (ä»…é™ç®¡ç†å‘˜)", expanded=True):
        pwd = st.text_input("è¾“å…¥ç®¡ç†å‘˜å¯†ç ", type="password")

        if pwd == ADMIN_PASSWORD:
            st.info("ğŸ”“ èº«ä»½éªŒè¯é€šè¿‡")
            with st.form("data_update_form", clear_on_submit=False):
                st.markdown("##### è¯·ä¸Šä¼ æ‰€æœ‰ 4 ä¸ªæ–‡ä»¶ï¼š")
                new_f = st.file_uploader("1. æ¼æ–—è¡¨ (funnel)", type=["xlsx", "csv"])
                new_d = st.file_uploader("2. é¡¾é—®è´¨æ£€è¡¨ (dcc)", type=["xlsx", "csv"])
                new_a = st.file_uploader("3. AMSè¡¨ (ams)", type=["xlsx", "csv"])
                # âœ… é—¨åº—æ’åè¡¨ï¼šæ¨èä¸Šä¼  xlsxï¼›ä¹Ÿå…è®¸csvå…œåº•
                new_s = st.file_uploader("4. é—¨åº—æ’åè¡¨ (store_rank)", type=["xlsx", "csv"])

                if st.form_submit_button("ğŸš€ ç¡®è®¤å¹¶æ›´æ–°æ•°æ®"):
                    if new_f and new_d and new_a and new_s:
                        with st.spinner("æ­£åœ¨ä¿å­˜å¹¶å¤„ç†..."):
                            # âœ… æ¸…ç†å†å²é”™è¯¯æ–‡ä»¶ï¼ˆä½ ä¹‹å‰æŠŠxlsxå†™æˆstore_rank.csvä¼šå¯¼è‡´è¯»csvè§£ç çˆ†ç‚¸ï¼‰
                            if os.path.exists(PATH_S_CSV) and os.path.exists(PATH_S_XLSX):
                                # ä¸¤ä¸ªéƒ½å­˜åœ¨æ—¶ï¼Œä¼˜å…ˆä¿ç•™xlsx
                                try:
                                    os.remove(PATH_S_CSV)
                                except Exception:
                                    pass

                            s1 = save_uploaded_file(new_f, PATH_F)
                            s2 = save_uploaded_file(new_d, PATH_D)
                            s3 = save_uploaded_file(new_a, PATH_A)

                            # âœ… æ ¹æ®ä¸Šä¼ çš„çœŸå®åç¼€ä¿å­˜ï¼ˆxlsx->xlsxï¼Œcsv->csvï¼‰
                            if new_s.name.lower().endswith(".xlsx"):
                                # åˆ é™¤æ—§csvï¼Œé¿å…è¯¯è¯»
                                if os.path.exists(PATH_S_CSV):
                                    try:
                                        os.remove(PATH_S_CSV)
                                    except Exception:
                                        pass
                                s4 = save_uploaded_file(new_s, PATH_S_XLSX)
                            else:
                                # åˆ é™¤æ—§xlsxï¼Œé¿å…æ··ä¹±
                                if os.path.exists(PATH_S_XLSX):
                                    try:
                                        os.remove(PATH_S_XLSX)
                                    except Exception:
                                        pass
                                s4 = save_uploaded_file(new_s, PATH_S_CSV)

                            if s1 and s2 and s3 and s4:
                                st.success("âœ… æ›´æ–°æˆåŠŸï¼æ­£åœ¨åˆ·æ–°é¡µé¢...")
                                st.rerun()
                    else:
                        st.error("âŒ è¯·ç¡®ä¿ 4 ä¸ªæ–‡ä»¶å…¨éƒ¨ä¸Šä¼ å®Œæ¯•ã€‚")
        elif pwd:
            st.error("å¯†ç é”™è¯¯")

# ================= 4. æ•°æ®å¤„ç† =================
def smart_read(file_path):
    """
    å¢å¼ºç‰ˆæ–‡ä»¶è¯»å–ï¼š
    - xlsx: read_excel(header=None)
    - csv: å¤šç¼–ç å°è¯• + on_bad_lines='skip'
    - é¢å¤–å…œåº•ï¼šå¦‚æœæ–‡ä»¶ç­¾åæ˜¯PK(å…¶å®æ˜¯xlsx)ï¼Œå³ä¾¿åç¼€æ˜¯csvä¹ŸæŒ‰xlsxè¯»ï¼ˆé¿å…å†æ¬¡ç‚¸ï¼‰
    """
    try:
        if not file_path or not os.path.exists(file_path):
            return None

        # âœ… å…œåº•ï¼šå†…å®¹ç­¾ååˆ¤æ–­ï¼ˆxlsxæ˜¯zip: PK..ï¼‰
        try:
            with open(file_path, "rb") as f:
                sig = f.read(4)
            if sig == b"PK\x03\x04":
                df = pd.read_excel(file_path, header=None)
            else:
                df = None
        except Exception:
            df = None

        # æ­£å¸¸åˆ†æ”¯
        if df is None:
            if file_path.lower().endswith(".xlsx"):
                try:
                    df = pd.read_excel(file_path, header=None)
                except Exception as e:
                    st.error(f"Excelè¯»å–é”™è¯¯ {os.path.basename(file_path)}: {e}")
                    return None
            else:
                encodings = ["utf-8-sig", "gb18030", "utf-16"]
                for enc in encodings:
                    try:
                        df = pd.read_csv(
                            file_path,
                            header=None,
                            encoding=enc,
                            engine="python",
                            on_bad_lines="skip"
                        )
                        break
                    except (UnicodeDecodeError, pd.errors.ParserError):
                        continue
                    except Exception:
                        continue

                if df is None:
                    st.error(f"âŒ æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶: {os.path.basename(file_path)}")
                    return None

        # æ™ºèƒ½å¯»æ‰¾è¡¨å¤´
        header_row = 0
        keywords = ["é—¨åº—", "é¡¾é—®", "ç®¡å®¶", "æ’å", "ä»£ç†å•†", "åºå·", "çº¿ç´¢"]

        if len(df) > 0:
            for i in range(min(8, len(df))):
                row_values = df.iloc[i].astype(str).str.cat(sep=",")
                if any(k in row_values for k in keywords):
                    header_row = i
                    break

        df.columns = df.iloc[header_row]
        df = df[header_row + 1:].reset_index(drop=True)

        # æ¸…ç†åˆ—å
        df.columns = (
            df.columns.astype(str)
            .str.strip()
            .str.replace("\n", "", regex=False)
            .str.replace("\r", "", regex=False)
        )

        # åˆ é™¤ç©ºåˆ—
        df = df.loc[:, df.columns.notna()]
        df = df.loc[:, df.columns != "nan"]

        return df

    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶ç³»ç»Ÿçº§å¤±è´¥: {os.path.basename(file_path)} - {e}")
        return None

def safe_div(df, num_col, denom_col):
    if num_col not in df.columns or denom_col not in df.columns:
        return 0
    num = pd.to_numeric(df[num_col], errors="coerce").fillna(0)
    denom = pd.to_numeric(df[denom_col], errors="coerce").fillna(0)
    return (num / denom).replace([np.inf, -np.inf], 0).fillna(0)

@st.cache_data(ttl=300)
def process_data(path_f, path_d, path_a, store_rank_path):
    try:
        raw_f = smart_read(path_f)
        raw_d = smart_read(path_d)
        raw_a = smart_read(path_a)
        raw_s = smart_read(store_rank_path)

        if raw_f is None or raw_d is None or raw_a is None or raw_s is None:
            return None, None

        # --- A. æ¼æ–—è¡¨å¤„ç† ---
        f_cols = raw_f.columns
        col_store = next((c for c in f_cols if "é—¨åº—" in c or "ä»£ç†" in c), "é—¨åº—åç§°")
        col_name  = next((c for c in f_cols if "é¡¾é—®" in c or "ç®¡å®¶" in c), "é‚€çº¦ä¸“å‘˜/ç®¡å®¶")
        col_leads = next((c for c in f_cols if "æœ‰æ•ˆçº¿ç´¢" in c or "çº¿ç´¢é‡" in c), "çº¿ç´¢é‡")
        col_visits = next((c for c in f_cols if "åˆ°åº—" in c and "ç‡" not in c), "åˆ°åº—é‡")

        df_f = raw_f.rename(columns={
            col_store: "é—¨åº—åç§°",
            col_name: "é‚€çº¦ä¸“å‘˜/ç®¡å®¶",
            col_leads: "çº¿ç´¢é‡",
            col_visits: "åˆ°åº—é‡"
        })

        mask_sub = df_f["é‚€çº¦ä¸“å‘˜/ç®¡å®¶"].astype(str).str.contains("å°è®¡", na=False)
        df_store_data = df_f[mask_sub].copy()
        df_advisor_data = df_f[~mask_sub].copy()

        for df in [df_store_data, df_advisor_data]:
            df["çº¿ç´¢é‡"] = pd.to_numeric(df["çº¿ç´¢é‡"], errors="coerce").fillna(0)
            df["åˆ°åº—é‡"] = pd.to_numeric(df["åˆ°åº—é‡"], errors="coerce").fillna(0)
            df["çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼"] = safe_div(df, "åˆ°åº—é‡", "çº¿ç´¢é‡")
            df["çº¿ç´¢åˆ°åº—ç‡"] = (df["çº¿ç´¢åˆ°åº—ç‡_æ•°å€¼"] * 100).map("{:.1f}%".format)

        # --- B. é¡¾é—®è´¨æ£€è¡¨ ---
        d_map = {
            "é¡¾é—®åç§°": "é‚€çº¦ä¸“å‘˜/ç®¡å®¶",
            "è´¨æ£€æ€»åˆ†": "è´¨æ£€æ€»åˆ†",
            "60ç§’é€šè¯": "S_60s",
            "ç”¨è½¦éœ€æ±‚": "S_Needs",
            "è½¦å‹ä¿¡æ¯": "S_Car",
            "æ”¿ç­–ç›¸å…³": "S_Policy",
            "æ˜ç¡®åˆ°åº—æ—¶é—´": "S_Time",
        }
        wechat_raw = next((c for c in raw_d.columns if "å¾®ä¿¡" in c and "æ·»åŠ " in c), "æ·»åŠ å¾®ä¿¡")
        df_d = raw_d.rename(columns=d_map)
        df_d["S_Wechat"] = df_d[wechat_raw] if wechat_raw in df_d.columns else 0

        num_cols = ["è´¨æ£€æ€»åˆ†", "S_60s", "S_Time", "S_Needs", "S_Car", "S_Policy", "S_Wechat"]
        for c in num_cols:
            if c in df_d.columns:
                df_d[c] = pd.to_numeric(df_d[c], errors="coerce")

        if "é‚€çº¦ä¸“å‘˜/ç®¡å®¶" not in df_d.columns and "ç®¡å®¶" in raw_d.columns:
            df_d.rename(columns={"ç®¡å®¶": "é‚€çº¦ä¸“å‘˜/ç®¡å®¶"}, inplace=True)

        # --- C. é—¨åº—æ’åè¡¨ ---
        s_map = {
            "60ç§’é€šè¯": "S_60s",
            "ç”¨è½¦éœ€æ±‚": "S_Needs",
            "è½¦å‹ä¿¡æ¯": "S_Car",
            "æ”¿ç­–ç›¸å…³": "S_Policy",
            "æ˜ç¡®åˆ°åº—æ—¶é—´": "S_Time",
        }
        s_wechat_raw = next((c for c in raw_s.columns if "å¾®ä¿¡" in c and "æ·»åŠ " in c), "æ·»åŠ å¾®ä¿¡")
        s_store_raw  = next((c for c in raw_s.columns if "é—¨åº—" in c and "ID" not in c), "é—¨åº—åç§°")

        df_s = raw_s.rename(columns={**s_map, s_store_raw: "é—¨åº—åç§°"})
        df_s["S_Wechat"] = df_s[s_wechat_raw] if s_wechat_raw in df_s.columns else 0

        for c in ["è´¨æ£€æ€»åˆ†", "S_60s", "S_Time"]:
            if c in df_s.columns:
                df_s[c] = pd.to_numeric(df_s[c], errors="coerce")

        # --- D. AMSè¡¨ ---
        a_map = {}
        for c in raw_a.columns:
            if "æ¥é€š" in c and "çº¿ç´¢" in c and "ç‡" not in c:
                a_map[c] = "conn_num"
            if "å¤–å‘¼" in c and "çº¿ç´¢" in c and "éœ€" not in c and "ç‡" not in c:
                a_map[c] = "conn_denom"
            if "ç®¡å®¶" in c or "é¡¾é—®" in c:
                a_map[c] = "é‚€çº¦ä¸“å‘˜/ç®¡å®¶"
            if "å¹³å‡é€šè¯æ—¶é•¿" in c:
                a_map[c] = "é€šè¯æ—¶é•¿"

        df_a = raw_a.rename(columns=a_map)

        for c in ["conn_num", "conn_denom", "é€šè¯æ—¶é•¿"]:
            if c not in df_a.columns:
                df_a[c] = 0
            else:
                df_a[c] = pd.to_numeric(df_a[c], errors="coerce").fillna(0)

        # --- E. åˆå¹¶ ---
        for df in [df_advisor_data, df_d, df_a, df_store_data, df_s]:
            if "é‚€çº¦ä¸“å‘˜/ç®¡å®¶" in df.columns:
                df["é‚€çº¦ä¸“å‘˜/ç®¡å®¶"] = df["é‚€çº¦ä¸“å‘˜/ç®¡å®¶"].astype(str).str.strip()
            if "é—¨åº—åç§°" in df.columns:
                df["é—¨åº—åç§°"] = df["é—¨åº—åç§°"].astype(str).str.strip()

        full_advisors = pd.merge(df_advisor_data, df_d, on="é‚€çº¦ä¸“å‘˜/ç®¡å®¶", how="left")

        if "é‚€çº¦ä¸“å‘˜/ç®¡å®¶" in df_a.columns:
            df_a_unique = df_a.groupby("é‚€çº¦ä¸“å‘˜/ç®¡å®¶").first().reset_index()
            full_advisors = pd.merge(full_advisors, df_a_unique, on="é‚€çº¦ä¸“å‘˜/ç®¡å®¶", how="left")

        if "conn_num" in full_advisors.columns and "é—¨åº—åç§°" in full_advisors.columns:
            ams_grp = full_advisors.groupby("é—¨åº—åç§°")[["conn_num", "conn_denom"]].sum().reset_index()
        else:
            ams_grp = pd.DataFrame(columns=["é—¨åº—åç§°", "conn_num", "conn_denom"])

        full_stores = pd.merge(df_store_data, df_s, on="é—¨åº—åç§°", how="left")
        full_stores = pd.merge(full_stores, ams_grp, on="é—¨åº—åç§°", how="left")

        return full_advisors, full_stores

    except Exception as e:
        import traceback
        st.error(f"æ•°æ®å¤„ç†é€»è¾‘é”™è¯¯: {e}")
        st.text(traceback.format_exc())
        return None, None

# ================= 5. ç•Œé¢æ¸²æŸ“ =================
store_rank_path = get_store_rank_path()
has_data = (
    os.path.exists(PATH_F)
    and os.path.exists(PATH_D)
    and os.path.exists(PATH_A)
    and (store_rank_path is not None)
)

if has_data:
    df_advisors, df_stores = process_data(PATH_F, PATH_D, PATH_A, store_rank_path)

    if df_advisors is not None:
        st.sidebar.markdown("---")
        if df_stores is not None and not df_stores.empty and "é—¨åº—åç§°" in df_stores.columns:
            store_options = ["å…¨éƒ¨"] + sorted(list(df_stores["é—¨åº—åç§°"].unique()))
        else:
            store_options = ["å…¨éƒ¨"]

        selected_store = st.sidebar.selectbox("ğŸ­ åˆ‡æ¢é—¨åº—è§†å›¾", store_options)

        if selected_store == "å…¨éƒ¨":
            current_df = df_stores.copy() if df_stores is not None else pd.DataFrame()
            current_df["Name"] = current_df.get("é—¨åº—åç§°", "")
            rank_title = "ğŸ† å…¨åŒºé—¨åº—æ’å"
        else:
            current_df = df_advisors[df_advisors.get("é—¨åº—åç§°", "") == selected_store].copy()
            current_df["Name"] = current_df.get("é‚€çº¦ä¸“å‘˜/ç®¡å®¶", "")
            rank_title = f"ğŸ‘¤ {selected_store} - é¡¾é—®æ’å"

        kpi_leads = current_df["çº¿ç´¢é‡"].sum() if "çº¿ç´¢é‡" in current_df.columns else 0
        kpi_visits = current_df["åˆ°åº—é‡"].sum() if "åˆ°åº—é‡" in current_df.columns else 0
        kpi_rate = (kpi_visits / kpi_leads) if kpi_leads > 0 else 0
        kpi_score = current_df["è´¨æ£€æ€»åˆ†"].mean() if "è´¨æ£€æ€»åˆ†" in current_df.columns else 0

        st.subheader("1ï¸âƒ£ ç»“æœæ¦‚è§ˆ (Result)")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("æ€»æœ‰æ•ˆçº¿ç´¢", f"{int(kpi_leads):,}")
        k2.metric("æ€»å®é™…åˆ°åº—", f"{int(kpi_visits):,}")
        k3.metric("çº¿ç´¢åˆ°åº—ç‡", f"{kpi_rate:.1%}")
        k4.metric("å¹³å‡è´¨æ£€æ€»åˆ†", f"{kpi_score:.1f}")

        st.markdown("---")

        c1, c2 = st.columns(2)
        with c1:
            st.subheader("é€šè¯è´¨é‡åˆ†æ")
            if "S_60s" in current_df.columns and "conn_num" in current_df.columns:
                current_df["æ¥é€šç‡"] = safe_div(current_df, "conn_num", "conn_denom")
                plot_df = current_df.fillna(0)
                fig = px.scatter(
                    plot_df,
                    x="æ¥é€šç‡",
                    y="S_60s",
                    size="çº¿ç´¢é‡" if "çº¿ç´¢é‡" in plot_df.columns else None,
                    color="è´¨æ£€æ€»åˆ†" if "è´¨æ£€æ€»åˆ†" in plot_df.columns else None,
                    hover_name="Name",
                    labels={"S_60s": "60ç§’é€šè¯å æ¯”", "æ¥é€šç‡": "å¤–å‘¼æ¥é€šç‡"},
                )
                fig.update_layout(xaxis_tickformat=".0%", height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("â„¹ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ˜¾ç¤ºé€šè¯è´¨é‡æ•£ç‚¹å›¾ (éœ€ AMS å’Œ è´¨æ£€æ•°æ®)")

        with c2:
            st.subheader(rank_title)
            show_cols = ["Name", "çº¿ç´¢åˆ°åº—ç‡", "è´¨æ£€æ€»åˆ†", "çº¿ç´¢é‡", "åˆ°åº—é‡"]
            if "S_60s" in current_df.columns:
                show_cols.append("S_60s")

            show_cols = [c for c in show_cols if c in current_df.columns]

            if not current_df.empty and show_cols:
                st.dataframe(
                    current_df[show_cols].sort_values("çº¿ç´¢é‡", ascending=False) if "çº¿ç´¢é‡" in current_df.columns else current_df[show_cols],
                    use_container_width=True,
                    height=400,
                    hide_index=True,
                )
            else:
                st.warning("æš‚æ— æ•°æ®")
else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼è¯·åœ¨å·¦ä¾§ç‚¹å‡»â€œæ›´æ–°æ•°æ®â€å¹¶ä¸Šä¼ æ–‡ä»¶ã€‚")
